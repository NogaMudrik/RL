{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpful resources:\n",
    "https://github.com/simoninithomas/Deep_reinforcement_learning_Course/blob/master/Q%20learning/FrozenLake/Q%20Learning%20with%20FrozenLake.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "Q-yiwx-dEz2N"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from importlib import reload  \n",
    "\n",
    "#import main_functions\n",
    "#main_functions = reload(main_functions)\n",
    "#from main_functions import * \n",
    "\n",
    "%run main_functions.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "KOxNUQHRL5t_"
   },
   "outputs": [],
   "source": [
    "og_4x4 = ['SFFF',\n",
    "'FHFH',\n",
    "'FFFH',\n",
    "'HFFG']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse Env. \n",
    "og_4x4_inv = [''.join([word[i] for word in og_4x4])  for i in range(len(og_4x4[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_FdoKdqM0qt",
    "outputId": "fd5f978f-8bfd-4411-e6c5-0fcb63cd29dc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v1', is_slippery=False, desc = og_4x4)\n",
    "\n",
    "env.reset()\n",
    "# visualize 4x4 frozen lake\n",
    "env.render()\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2U4M9EydYhrn",
    "outputId": "c50fa0a8-7932-4a44-88df-3435be54020f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States =  16\n",
      "Actions =  4\n"
     ]
    }
   ],
   "source": [
    "# Total number of States and Actions\n",
    "n_states = env.observation_space.n\n",
    "n_actions = env.action_space.n\n",
    "n_rows = 4\n",
    "n_cols = 4\n",
    "print( \"States = \", n_states)\n",
    "print( \"Actions = \", n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "bc9jRORuNFkd"
   },
   "outputs": [],
   "source": [
    "##assign index to each state using state-matrix\n",
    "\n",
    "state_matrix = np.arange(0,n_states).reshape(n_rows,n_cols)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "_8BCvWMUNTYE"
   },
   "outputs": [],
   "source": [
    "#### Initialize Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "DWl1X4Mk30No",
    "outputId": "e48979b7-f581-45be-9fc3-7e93e1ab98e9"
   },
   "outputs": [],
   "source": [
    "Q = pd.DataFrame(np.random.rand(n_states,n_actions)/1000)\n",
    "Q.loc[15] = np.zeros(n_actions,)\n",
    "#Q = restrict_actions(Q, n_states, n_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "Hj5IskDPPcCT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.7992\n",
      "Episode: 10 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.7912438682636309\n",
      "Episode: 20 Reward: 0.0 Steps Taken: 7 Terminal State: F, Epsilon: 0.7833669407717642\n",
      "Episode: 30 Reward: 0.0 Steps Taken: 7 Terminal State: F, Epsilon: 0.7755684290366581\n",
      "Episode: 40 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.7678475524200608\n",
      "Episode: 50 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.7602035380550674\n",
      "Episode: 60 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.7526356207687559\n",
      "Episode: 70 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.7451430430055925\n",
      "Episode: 80 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.7377250547515992\n",
      "Episode: 90 Reward: 0.0 Steps Taken: 6 Terminal State: F, Epsilon: 0.7303809134592769\n",
      "Episode: 100 Reward: 0.0 Steps Taken: 8 Terminal State: F, Epsilon: 0.7231098839732764\n",
      "Episode: 110 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.7159112384568073\n",
      "Episode: 120 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.7087842563187822\n",
      "Episode: 130 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.7017282241416841\n",
      "Episode: 140 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.694742435610153\n",
      "Episode: 150 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.6878261914402828\n",
      "Episode: 160 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.6809787993096221\n",
      "Episode: 170 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.6741995737878729\n",
      "Episode: 180 Reward: 1.0 Steps Taken: 26 Terminal State: G, Epsilon: 0.6674878362682779\n",
      "Episode: 190 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.6608429148996913\n",
      "Episode: 200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.6542641445193258\n",
      "Episode: 210 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.6477508665861693\n",
      "Episode: 220 Reward: 0.0 Steps Taken: 8 Terminal State: F, Epsilon: 0.6413024291150646\n",
      "Episode: 230 Reward: 0.0 Steps Taken: 15 Terminal State: H, Epsilon: 0.6349181866114447\n",
      "Episode: 240 Reward: 0.0 Steps Taken: 6 Terminal State: F, Epsilon: 0.6285975000067183\n",
      "Episode: 250 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.6223397365942986\n",
      "Episode: 260 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.6161442699662687\n",
      "Episode: 270 Reward: 1.0 Steps Taken: 13 Terminal State: G, Epsilon: 0.6100104799506774\n",
      "Episode: 280 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.6039377525494594\n",
      "Episode: 290 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.5979254798769741\n",
      "Episode: 300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.5919730600991551\n",
      "Episode: 310 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.5860798973732659\n",
      "Episode: 320 Reward: 0.0 Steps Taken: 9 Terminal State: F, Epsilon: 0.5802454017882566\n",
      "Episode: 330 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.5744689893057117\n",
      "Episode: 340 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.5687500817013885\n",
      "Episode: 350 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.5630881065073355\n",
      "Episode: 360 Reward: 1.0 Steps Taken: 11 Terminal State: G, Epsilon: 0.557482496954589\n",
      "Episode: 370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.5519326919164373\n",
      "Episode: 380 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.5464381358522531\n",
      "Episode: 390 Reward: 1.0 Steps Taken: 12 Terminal State: G, Epsilon: 0.5409982787518822\n",
      "Episode: 400 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.5356125760805872\n",
      "Episode: 410 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.5302804887245397\n",
      "Episode: 420 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.5250014829368536\n",
      "Episode: 430 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.5197750302841573\n",
      "Episode: 440 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.5146006075936969\n",
      "Episode: 450 Reward: 0.0 Steps Taken: 7 Terminal State: F, Epsilon: 0.5094776969009654\n",
      "Episode: 460 Reward: 0.0 Steps Taken: 4 Terminal State: F, Epsilon: 0.5044057853978547\n",
      "Episode: 470 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.49938436538132314\n",
      "Episode: 480 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.4944129342025731\n",
      "Episode: 490 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.48949099421673664\n",
      "Episode: 500 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.48461805273305963\n",
      "Episode: 510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.47979362196558345\n",
      "Episode: 520 Reward: 1.0 Steps Taken: 11 Terminal State: G, Epsilon: 0.4750172189843173\n",
      "Episode: 530 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.47028836566689614\n",
      "Episode: 540 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.46560658865072047\n",
      "Episode: 550 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.460971419285572\n",
      "Episode: 560 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.4563823935867017\n",
      "Episode: 570 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.45183905218838427\n",
      "Episode: 580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.44734094029793514\n",
      "Episode: 590 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.4428876076501854\n",
      "Episode: 600 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.4384786084624098\n",
      "Episode: 610 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.4341135013897036\n",
      "Episode: 620 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.4297918494808035\n",
      "Episode: 630 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.4255132201343483\n",
      "Episode: 640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.42127718505557504\n",
      "Episode: 650 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.41708332021344663\n",
      "Episode: 660 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.4129312057982058\n",
      "Episode: 670 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.4088204261793515\n",
      "Episode: 680 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.40475056986403424\n",
      "Episode: 690 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.4007212294558651\n",
      "Episode: 700 Reward: 1.0 Steps Taken: 11 Terminal State: G, Epsilon: 0.3967320016141349\n",
      "Episode: 710 Reward: 0.0 Steps Taken: 7 Terminal State: F, Epsilon: 0.3927824870134399\n",
      "Episode: 720 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.38887229030370796\n",
      "Episode: 730 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.385001020070625\n",
      "Episode: 740 Reward: 1.0 Steps Taken: 14 Terminal State: G, Epsilon: 0.3811682887964528\n",
      "Episode: 750 Reward: 0.0 Steps Taken: 9 Terminal State: F, Epsilon: 0.37737371282123877\n",
      "Episode: 760 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.3736169123044112\n",
      "Episode: 770 Reward: 1.0 Steps Taken: 11 Terminal State: G, Epsilon: 0.36989751118675673\n",
      "Episode: 780 Reward: 0.0 Steps Taken: 13 Terminal State: F, Epsilon: 0.36621513715277654\n",
      "Episode: 790 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.36256942159341715\n",
      "Episode: 800 Reward: 0.0 Steps Taken: 6 Terminal State: F, Epsilon: 0.3589599995691724\n",
      "Episode: 810 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.3553865097735525\n",
      "Episode: 820 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.3518485944969173\n",
      "Episode: 830 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.34834589959066875\n",
      "Episode: 840 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.34487807443180063\n",
      "Episode: 850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.3414447718878007\n",
      "Episode: 860 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.33804564828190237\n",
      "Episode: 870 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.33468036335868273\n",
      "Episode: 880 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.3313485802500021\n",
      "Episode: 890 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.3280499654412834\n",
      "Episode: 900 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.32478418873812753\n",
      "Episode: 910 Reward: 0.0 Steps Taken: 11 Terminal State: H, Epsilon: 0.32155092323325973\n",
      "Episode: 920 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.3183498452738065\n",
      "Episode: 930 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.3151806344288976\n",
      "Episode: 940 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.31204297345759036\n",
      "Episode: 950 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.3089365482771137\n",
      "Episode: 960 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.30586104793142815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 970 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.30281616456009885\n",
      "Episode: 980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.29980159336747847\n",
      "Episode: 990 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.29681703259219694\n",
      "Episode: 1000 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.2938621834769546\n",
      "Episode: 1010 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.2909367502386166\n",
      "Episode: 1020 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.28804044003860463\n",
      "Episode: 1030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.28517296295358346\n",
      "Episode: 1040 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.28233403194643947\n",
      "Episode: 1050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.27952336283754786\n",
      "Episode: 1060 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.2767406742763261\n",
      "Episode: 1070 Reward: 0.0 Steps Taken: 7 Terminal State: F, Epsilon: 0.27398568771307025\n",
      "Episode: 1080 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.2712581273710722\n",
      "Episode: 1090 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.2685577202190138\n",
      "Episode: 1100 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.26588419594363666\n",
      "Episode: 1110 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.263237286922683\n",
      "Episode: 1120 Reward: 0.0 Steps Taken: 8 Terminal State: F, Epsilon: 0.2606167281981068\n",
      "Episode: 1130 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.25802225744955115\n",
      "Episode: 1140 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.25545361496808977\n",
      "Episode: 1150 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.2529105436302295\n",
      "Episode: 1160 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.2503927888721729\n",
      "Episode: 1170 Reward: 0.0 Steps Taken: 6 Terminal State: F, Epsilon: 0.24790009866433518\n",
      "Episode: 1180 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.2454322234861165\n",
      "Episode: 1190 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.24298891630092442\n",
      "Episode: 1200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.24056993253144524\n",
      "Episode: 1210 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.2381750300351619\n",
      "Episode: 1220 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.23580396908011508\n",
      "Episode: 1230 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.23345651232090572\n",
      "Episode: 1240 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.2311324247749367\n",
      "Episode: 1250 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.22883147379889088\n",
      "Episode: 1260 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.22655342906544304\n",
      "Episode: 1270 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.22429806254020423\n",
      "Episode: 1280 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.2220651484588951\n",
      "Episode: 1290 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.21985446330474676\n",
      "Episode: 1300 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.2176657857861265\n",
      "Episode: 1310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.21549889681438633\n",
      "Episode: 1320 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.21335357948193198\n",
      "Episode: 1330 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.21122961904051035\n",
      "Episode: 1340 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.2091268028797128\n",
      "Episode: 1350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.20704492050569293\n",
      "Episode: 1360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.20498376352009562\n",
      "Episode: 1370 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.20294312559919642\n",
      "Episode: 1380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.20092280247324829\n",
      "Episode: 1390 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.198922591906034\n",
      "Episode: 1400 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.19694229367462207\n",
      "Episode: 1410 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.19498170954932426\n",
      "Episode: 1420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1930406432738527\n",
      "Episode: 1430 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.19111890054567424\n",
      "Episode: 1440 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.18921628899656084\n",
      "Episode: 1450 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.18733261817333322\n",
      "Episode: 1460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1854676995187962\n",
      "Episode: 1470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.18362134635286415\n",
      "Episode: 1480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1817933738538741\n",
      "Episode: 1490 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.17998359904008476\n",
      "Episode: 1500 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.1781918407513601\n",
      "Episode: 1510 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.17641791963103487\n",
      "Episode: 1520 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1746616581079609\n",
      "Episode: 1530 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.17292288037873216\n",
      "Episode: 1540 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.17120141239008646\n",
      "Episode: 1550 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.16949708182148285\n",
      "Episode: 1560 Reward: 0.0 Steps Taken: 7 Terminal State: F, Epsilon: 0.16780971806785186\n",
      "Episode: 1570 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.16613915222251802\n",
      "Episode: 1580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.16448521706029195\n",
      "Episode: 1590 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.1628477470207312\n",
      "Episode: 1600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.16122657819156724\n",
      "Episode: 1610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.15962154829229783\n",
      "Episode: 1620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1580324966579425\n",
      "Episode: 1630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.15645926422296014\n",
      "Episode: 1640 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.1549016935053259\n",
      "Episode: 1650 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.15335962859076752\n",
      "Episode: 1660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.15183291511715788\n",
      "Episode: 1670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.15032140025906346\n",
      "Episode: 1680 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.14882493271244615\n",
      "Episode: 1690 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1473433626795176\n",
      "Episode: 1700 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.14587654185374446\n",
      "Episode: 1710 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.14442432340500275\n",
      "Episode: 1720 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.14298656196487988\n",
      "Episode: 1730 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.14156311361212323\n",
      "Episode: 1740 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.14015383585823352\n",
      "Episode: 1750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1387585876332015\n",
      "Episode: 1760 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.13737722927138682\n",
      "Episode: 1770 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.13600962249753726\n",
      "Episode: 1780 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.13465563041294734\n",
      "Episode: 1790 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.13331511748175456\n",
      "Episode: 1800 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.13198794951737225\n",
      "Episode: 1810 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.13067399366905708\n",
      "Episode: 1820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.12937311840861102\n",
      "Episode: 1830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.12808519351721487\n",
      "Episode: 1840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.12681009007239344\n",
      "Episode: 1850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.12554768043511014\n",
      "Episode: 1860 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.12429783823699037\n",
      "Episode: 1870 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.12306043836767178\n",
      "Episode: 1880 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.1218353569622807\n",
      "Episode: 1890 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.12062247138903309\n",
      "Episode: 1900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11942166023695906\n",
      "Episode: 1910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1182328033037494\n",
      "Episode: 1920 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.11705578158372329\n",
      "Episode: 1930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11589047725591577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1940 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.11473677367228365\n",
      "Episode: 1950 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11359455534602904\n",
      "Episode: 1960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11246370794003893\n",
      "Episode: 1970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11134411825543995\n",
      "Episode: 1980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11023567422026707\n",
      "Episode: 1990 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.10913826487824516\n",
      "Episode: 2000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.108051780377682\n",
      "Episode: 2010 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.10697611196047219\n",
      "Episode: 2020 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1059111519512103\n",
      "Episode: 2030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.10485679374641242\n",
      "Episode: 2040 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.10381293180384518\n",
      "Episode: 2050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.10277946163196065\n",
      "Episode: 2060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1017562797794369\n",
      "Episode: 2070 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.10074328382482223\n",
      "Episode: 2080 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2090 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2110 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2120 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2130 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2140 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2150 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2160 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 2170 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2180 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 2190 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2210 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2220 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2230 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2240 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2270 Reward: 0.0 Steps Taken: 7 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 2280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2290 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2320 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2330 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2350 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2380 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 2390 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2410 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2430 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2440 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2450 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2470 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2490 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2500 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2510 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2520 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2540 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2560 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 2570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2650 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 2660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2670 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2690 Reward: 0.0 Steps Taken: 7 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 2700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2710 Reward: 0.0 Steps Taken: 4 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 2720 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2730 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2740 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2760 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2770 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2780 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2790 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2810 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2860 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2870 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2920 Reward: 0.0 Steps Taken: 6 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 2930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2950 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2970 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2980 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2990 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3000 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3010 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3020 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3030 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 3040 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3050 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3070 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3080 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 3090 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3100 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 3110 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3120 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3130 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3140 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3150 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3160 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3190 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3210 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3220 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3230 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3240 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3250 Reward: 0.0 Steps Taken: 4 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 3260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3270 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3290 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3300 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3320 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3330 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3350 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3390 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3410 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3430 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3440 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3460 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3470 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3490 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3500 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3520 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3540 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3560 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3600 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3640 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3690 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3720 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3730 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3740 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3750 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 3760 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3770 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3780 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3790 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3800 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3810 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3830 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 3840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3860 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3870 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3880 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3910 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3920 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3930 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3950 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4010 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4020 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4040 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4060 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4070 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4080 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4090 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4110 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4120 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4130 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4140 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4150 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4160 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4190 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4200 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4210 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4220 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4230 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4240 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4270 Reward: 1.0 Steps Taken: 12 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4290 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4320 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4330 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4350 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4370 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4390 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4400 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4410 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4430 Reward: 1.0 Steps Taken: 12 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4440 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4470 Reward: 0.0 Steps Taken: 4 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 4480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4490 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4500 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4520 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4540 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4560 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4610 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4620 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4630 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4660 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 4670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4690 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4700 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4720 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 4730 Reward: 0.0 Steps Taken: 7 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 4740 Reward: 0.0 Steps Taken: 6 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 4750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4770 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4780 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4790 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4810 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4820 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4840 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4860 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4870 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4890 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4910 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4920 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4930 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4950 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4970 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4980 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5000 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5010 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5020 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5040 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5050 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5070 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5080 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5090 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5100 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5110 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5120 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5130 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5140 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5150 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5160 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5170 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5190 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5210 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5220 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 5230 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 5240 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 5250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5270 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5290 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5320 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5330 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5340 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5360 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5390 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5410 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 5420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5430 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5440 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5490 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5500 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5520 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5530 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 5540 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5560 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 5570 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5650 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5690 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5700 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5720 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5730 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5760 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5770 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5780 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5790 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5810 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5830 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5860 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5870 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5900 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 5910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5920 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5950 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5970 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6010 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6020 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6030 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6040 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6060 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6070 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6080 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6090 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6110 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6120 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6130 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6140 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6150 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6160 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6190 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6200 Reward: 0.0 Steps Taken: 6 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 6210 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6220 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6230 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6240 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6270 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6280 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6290 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6310 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6320 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6330 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6380 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6390 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6410 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6420 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6430 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6440 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6490 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6500 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6520 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6540 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6560 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 6570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6610 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6650 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 6670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6680 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6690 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 6700 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 6710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6720 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6730 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6770 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6780 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6790 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6810 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6850 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6860 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6870 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 6880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6920 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6950 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6960 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6990 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7000 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7010 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7020 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7040 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7060 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7070 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7080 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7090 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7110 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7120 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7130 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7140 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7150 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7160 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7170 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7190 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7210 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7220 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7230 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7240 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7260 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7270 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7290 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7320 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7330 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 7340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7390 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7400 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7410 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7420 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 7430 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7440 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7460 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7470 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7490 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7500 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7520 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7540 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7560 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7570 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7580 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 7600 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7610 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7640 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7690 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7720 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7730 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7750 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7770 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7780 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7790 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7810 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7860 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7870 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 7880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7920 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7950 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8010 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8020 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8040 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8070 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8080 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8090 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8110 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8120 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8130 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8140 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8150 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8160 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 8170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8190 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8210 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8220 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8230 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8240 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8270 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8280 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8290 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8310 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8320 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8330 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8350 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 8360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8390 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 8400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8410 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8430 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 8440 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8470 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8490 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8500 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8510 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8520 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8530 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8540 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 8550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8560 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8590 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8620 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8660 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8680 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8690 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8720 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8730 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8770 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8780 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8790 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8800 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8810 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8850 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8860 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8870 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8900 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8910 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8920 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8950 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8960 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8970 Reward: 0.0 Steps Taken: 7 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 8980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9010 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9020 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9040 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9050 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9070 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9080 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9090 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9110 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9120 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9130 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9140 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9150 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9160 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9170 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9180 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9190 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9200 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9210 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9220 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9230 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9240 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9270 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9280 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9290 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9320 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9330 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9390 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9400 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9410 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9430 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9440 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9470 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9490 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9500 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 9520 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9540 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9560 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 9570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9590 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9630 Reward: 0.0 Steps Taken: 3 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 9640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9660 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9670 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9690 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9720 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9730 Reward: 0.0 Steps Taken: 5 Terminal State: F, Epsilon: 0.09994015273159322\n",
      "Episode: 9740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9770 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9780 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9790 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9810 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9820 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9860 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9870 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9920 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9950 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.8\n",
    "epsilon_final = 0.1\n",
    "epsilon_decay = 0.999\n",
    "gamma = 0.90 # discount factor\n",
    "learning_rate = 0.9 #how important is the difference between q-val from q-table and what's observed\n",
    "num_episodes = 10000\n",
    "\n",
    "terminal_state_inv, steps_total_inv, rewards_total_inv, epsilon_total_inv, Q = train_model(Q , env, num_episodes,  epsilon_final, epsilon , epsilon_decay ,  learning_rate,  gamma  )        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "ZZWfuWX-PiV3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# steps_total = [] # store number of steps taken in each episode\n",
    "# rewards_total = [] #store reward obtained for each episode\n",
    "# epsilon_total = [] #store epsilon obtained at the end of each episode\n",
    "# terminal_state = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ai7-U-UJQLO7",
    "outputId": "6bebee96-7b20-4801-c6cf-f91cfa287f26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.7992\n",
      "Episode: 10 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.7912438682636309\n",
      "Episode: 20 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.7833669407717642\n",
      "Episode: 30 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.7755684290366581\n",
      "Episode: 40 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.7678475524200608\n",
      "Episode: 50 Reward: 0.0 Steps Taken: 10 Terminal State: H, Epsilon: 0.7602035380550674\n",
      "Episode: 60 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.7526356207687559\n",
      "Episode: 70 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.7451430430055925\n",
      "Episode: 80 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.7377250547515992\n",
      "Episode: 90 Reward: 0.0 Steps Taken: 10 Terminal State: H, Epsilon: 0.7303809134592769\n",
      "Episode: 100 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.7231098839732764\n",
      "Episode: 110 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.7159112384568073\n",
      "Episode: 120 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.7087842563187822\n",
      "Episode: 130 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.7017282241416841\n",
      "Episode: 140 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.694742435610153\n",
      "Episode: 150 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.6878261914402828\n",
      "Episode: 160 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.6809787993096221\n",
      "Episode: 170 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.6741995737878729\n",
      "Episode: 180 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.6674878362682779\n",
      "Episode: 190 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.6608429148996913\n",
      "Episode: 200 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.6542641445193258\n",
      "Episode: 210 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.6477508665861693\n",
      "Episode: 220 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.6413024291150646\n",
      "Episode: 230 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.6349181866114447\n",
      "Episode: 240 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.6285975000067183\n",
      "Episode: 250 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.6223397365942986\n",
      "Episode: 260 Reward: 1.0 Steps Taken: 14 Terminal State: G, Epsilon: 0.6161442699662687\n",
      "Episode: 270 Reward: 0.0 Steps Taken: 12 Terminal State: H, Epsilon: 0.6100104799506774\n",
      "Episode: 280 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.6039377525494594\n",
      "Episode: 290 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.5979254798769741\n",
      "Episode: 300 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.5919730600991551\n",
      "Episode: 310 Reward: 0.0 Steps Taken: 10 Terminal State: H, Epsilon: 0.5860798973732659\n",
      "Episode: 320 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.5802454017882566\n",
      "Episode: 330 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.5744689893057117\n",
      "Episode: 340 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.5687500817013885\n",
      "Episode: 350 Reward: 0.0 Steps Taken: 14 Terminal State: H, Epsilon: 0.5630881065073355\n",
      "Episode: 360 Reward: 0.0 Steps Taken: 12 Terminal State: H, Epsilon: 0.557482496954589\n",
      "Episode: 370 Reward: 1.0 Steps Taken: 17 Terminal State: G, Epsilon: 0.5519326919164373\n",
      "Episode: 380 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.5464381358522531\n",
      "Episode: 390 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.5409982787518822\n",
      "Episode: 400 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.5356125760805872\n",
      "Episode: 410 Reward: 0.0 Steps Taken: 10 Terminal State: H, Epsilon: 0.5302804887245397\n",
      "Episode: 420 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.5250014829368536\n",
      "Episode: 430 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.5197750302841573\n",
      "Episode: 440 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.5146006075936969\n",
      "Episode: 450 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.5094776969009654\n",
      "Episode: 460 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.5044057853978547\n",
      "Episode: 470 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.49938436538132314\n",
      "Episode: 480 Reward: 0.0 Steps Taken: 12 Terminal State: H, Epsilon: 0.4944129342025731\n",
      "Episode: 490 Reward: 1.0 Steps Taken: 12 Terminal State: G, Epsilon: 0.48949099421673664\n",
      "Episode: 500 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.48461805273305963\n",
      "Episode: 510 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.47979362196558345\n",
      "Episode: 520 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.4750172189843173\n",
      "Episode: 530 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.47028836566689614\n",
      "Episode: 540 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.46560658865072047\n",
      "Episode: 550 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.460971419285572\n",
      "Episode: 560 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.4563823935867017\n",
      "Episode: 570 Reward: 1.0 Steps Taken: 12 Terminal State: G, Epsilon: 0.45183905218838427\n",
      "Episode: 580 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.44734094029793514\n",
      "Episode: 590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.4428876076501854\n",
      "Episode: 600 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.4384786084624098\n",
      "Episode: 610 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.4341135013897036\n",
      "Episode: 620 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.4297918494808035\n",
      "Episode: 630 Reward: 1.0 Steps Taken: 12 Terminal State: G, Epsilon: 0.4255132201343483\n",
      "Episode: 640 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.42127718505557504\n",
      "Episode: 650 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.41708332021344663\n",
      "Episode: 660 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.4129312057982058\n",
      "Episode: 670 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.4088204261793515\n",
      "Episode: 680 Reward: 0.0 Steps Taken: 16 Terminal State: H, Epsilon: 0.40475056986403424\n",
      "Episode: 690 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.4007212294558651\n",
      "Episode: 700 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.3967320016141349\n",
      "Episode: 710 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.3927824870134399\n",
      "Episode: 720 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.38887229030370796\n",
      "Episode: 730 Reward: 0.0 Steps Taken: 13 Terminal State: H, Epsilon: 0.385001020070625\n",
      "Episode: 740 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.3811682887964528\n",
      "Episode: 750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.37737371282123877\n",
      "Episode: 760 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.3736169123044112\n",
      "Episode: 770 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.36989751118675673\n",
      "Episode: 780 Reward: 1.0 Steps Taken: 15 Terminal State: G, Epsilon: 0.36621513715277654\n",
      "Episode: 790 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.36256942159341715\n",
      "Episode: 800 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.3589599995691724\n",
      "Episode: 810 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.3553865097735525\n",
      "Episode: 820 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.3518485944969173\n",
      "Episode: 830 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.34834589959066875\n",
      "Episode: 840 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.34487807443180063\n",
      "Episode: 850 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.3414447718878007\n",
      "Episode: 860 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.33804564828190237\n",
      "Episode: 870 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.33468036335868273\n",
      "Episode: 880 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.3313485802500021\n",
      "Episode: 890 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.3280499654412834\n",
      "Episode: 900 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.32478418873812753\n",
      "Episode: 910 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.32155092323325973\n",
      "Episode: 920 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.3183498452738065\n",
      "Episode: 930 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.3151806344288976\n",
      "Episode: 940 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.31204297345759036\n",
      "Episode: 950 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.3089365482771137\n",
      "Episode: 960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.30586104793142815\n",
      "Episode: 970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.30281616456009885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.29980159336747847\n",
      "Episode: 990 Reward: 1.0 Steps Taken: 11 Terminal State: G, Epsilon: 0.29681703259219694\n",
      "Episode: 1000 Reward: 1.0 Steps Taken: 13 Terminal State: G, Epsilon: 0.2938621834769546\n",
      "Episode: 1010 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.2909367502386166\n",
      "Episode: 1020 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.28804044003860463\n",
      "Episode: 1030 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.28517296295358346\n",
      "Episode: 1040 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.28233403194643947\n",
      "Episode: 1050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.27952336283754786\n",
      "Episode: 1060 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.2767406742763261\n",
      "Episode: 1070 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.27398568771307025\n",
      "Episode: 1080 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.2712581273710722\n",
      "Episode: 1090 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.2685577202190138\n",
      "Episode: 1100 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.26588419594363666\n",
      "Episode: 1110 Reward: 1.0 Steps Taken: 13 Terminal State: G, Epsilon: 0.263237286922683\n",
      "Episode: 1120 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.2606167281981068\n",
      "Episode: 1130 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.25802225744955115\n",
      "Episode: 1140 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.25545361496808977\n",
      "Episode: 1150 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.2529105436302295\n",
      "Episode: 1160 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.2503927888721729\n",
      "Episode: 1170 Reward: 1.0 Steps Taken: 13 Terminal State: G, Epsilon: 0.24790009866433518\n",
      "Episode: 1180 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.2454322234861165\n",
      "Episode: 1190 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.24298891630092442\n",
      "Episode: 1200 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.24056993253144524\n",
      "Episode: 1210 Reward: 1.0 Steps Taken: 12 Terminal State: G, Epsilon: 0.2381750300351619\n",
      "Episode: 1220 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.23580396908011508\n",
      "Episode: 1230 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.23345651232090572\n",
      "Episode: 1240 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.2311324247749367\n",
      "Episode: 1250 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.22883147379889088\n",
      "Episode: 1260 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.22655342906544304\n",
      "Episode: 1270 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.22429806254020423\n",
      "Episode: 1280 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.2220651484588951\n",
      "Episode: 1290 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.21985446330474676\n",
      "Episode: 1300 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.2176657857861265\n",
      "Episode: 1310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.21549889681438633\n",
      "Episode: 1320 Reward: 1.0 Steps Taken: 12 Terminal State: G, Epsilon: 0.21335357948193198\n",
      "Episode: 1330 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.21122961904051035\n",
      "Episode: 1340 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.2091268028797128\n",
      "Episode: 1350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.20704492050569293\n",
      "Episode: 1360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.20498376352009562\n",
      "Episode: 1370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.20294312559919642\n",
      "Episode: 1380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.20092280247324829\n",
      "Episode: 1390 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.198922591906034\n",
      "Episode: 1400 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.19694229367462207\n",
      "Episode: 1410 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.19498170954932426\n",
      "Episode: 1420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1930406432738527\n",
      "Episode: 1430 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.19111890054567424\n",
      "Episode: 1440 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.18921628899656084\n",
      "Episode: 1450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.18733261817333322\n",
      "Episode: 1460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1854676995187962\n",
      "Episode: 1470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.18362134635286415\n",
      "Episode: 1480 Reward: 0.0 Steps Taken: 10 Terminal State: H, Epsilon: 0.1817933738538741\n",
      "Episode: 1490 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.17998359904008476\n",
      "Episode: 1500 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1781918407513601\n",
      "Episode: 1510 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.17641791963103487\n",
      "Episode: 1520 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.1746616581079609\n",
      "Episode: 1530 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.17292288037873216\n",
      "Episode: 1540 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.17120141239008646\n",
      "Episode: 1550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.16949708182148285\n",
      "Episode: 1560 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.16780971806785186\n",
      "Episode: 1570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.16613915222251802\n",
      "Episode: 1580 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.16448521706029195\n",
      "Episode: 1590 Reward: 1.0 Steps Taken: 13 Terminal State: G, Epsilon: 0.1628477470207312\n",
      "Episode: 1600 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.16122657819156724\n",
      "Episode: 1610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.15962154829229783\n",
      "Episode: 1620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1580324966579425\n",
      "Episode: 1630 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.15645926422296014\n",
      "Episode: 1640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1549016935053259\n",
      "Episode: 1650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.15335962859076752\n",
      "Episode: 1660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.15183291511715788\n",
      "Episode: 1670 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.15032140025906346\n",
      "Episode: 1680 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.14882493271244615\n",
      "Episode: 1690 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.1473433626795176\n",
      "Episode: 1700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.14587654185374446\n",
      "Episode: 1710 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.14442432340500275\n",
      "Episode: 1720 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.14298656196487988\n",
      "Episode: 1730 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.14156311361212323\n",
      "Episode: 1740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.14015383585823352\n",
      "Episode: 1750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1387585876332015\n",
      "Episode: 1760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.13737722927138682\n",
      "Episode: 1770 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.13600962249753726\n",
      "Episode: 1780 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.13465563041294734\n",
      "Episode: 1790 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.13331511748175456\n",
      "Episode: 1800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.13198794951737225\n",
      "Episode: 1810 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.13067399366905708\n",
      "Episode: 1820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.12937311840861102\n",
      "Episode: 1830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.12808519351721487\n",
      "Episode: 1840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.12681009007239344\n",
      "Episode: 1850 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.12554768043511014\n",
      "Episode: 1860 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.12429783823699037\n",
      "Episode: 1870 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.12306043836767178\n",
      "Episode: 1880 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.1218353569622807\n",
      "Episode: 1890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.12062247138903309\n",
      "Episode: 1900 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.11942166023695906\n",
      "Episode: 1910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1182328033037494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1920 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11705578158372329\n",
      "Episode: 1930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11589047725591577\n",
      "Episode: 1940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11473677367228365\n",
      "Episode: 1950 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11359455534602904\n",
      "Episode: 1960 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.11246370794003893\n",
      "Episode: 1970 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.11134411825543995\n",
      "Episode: 1980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11023567422026707\n",
      "Episode: 1990 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.10913826487824516\n",
      "Episode: 2000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.108051780377682\n",
      "Episode: 2010 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.10697611196047219\n",
      "Episode: 2020 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1059111519512103\n",
      "Episode: 2030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.10485679374641242\n",
      "Episode: 2040 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.10381293180384518\n",
      "Episode: 2050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.10277946163196065\n",
      "Episode: 2060 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.1017562797794369\n",
      "Episode: 2070 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.10074328382482223\n",
      "Episode: 2080 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2090 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2110 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2120 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2130 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2140 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2150 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2160 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2190 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2210 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2220 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2230 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2240 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2270 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2290 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2320 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2330 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2340 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2390 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2400 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2410 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2420 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2430 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2440 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2460 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2480 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2490 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2500 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2520 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2540 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2560 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2590 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2620 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2670 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2690 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2720 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2730 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2750 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2760 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2770 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2780 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2790 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2810 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2830 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2860 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2870 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2880 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2890 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2920 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2940 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2950 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2960 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2990 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3010 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3020 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3040 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3070 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3080 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3090 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3110 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3120 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3130 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3140 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3150 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3160 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3190 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3200 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3210 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3220 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3230 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3240 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3270 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3290 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3300 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3310 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3320 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3330 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3350 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3360 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3370 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3390 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3400 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3410 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3430 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3440 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3490 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3500 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3520 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3540 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3560 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3600 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3640 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3660 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3670 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3690 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3720 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3730 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3740 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3770 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3780 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3790 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3810 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3830 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3860 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3870 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3920 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3950 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4010 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4020 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4040 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4060 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4070 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4080 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4090 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4110 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4120 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4130 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4140 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4150 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4160 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4190 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4210 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4220 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4230 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4240 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4250 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4270 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4280 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4290 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4300 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4320 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4330 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4340 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4370 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4390 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4410 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4420 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4430 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4440 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4480 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4490 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4500 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4520 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4540 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4560 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4600 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4630 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4640 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4690 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4700 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4720 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4730 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4740 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4770 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4780 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4790 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4810 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4820 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4860 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4870 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4880 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4920 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4930 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4940 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4950 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5000 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5010 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5020 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5030 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5040 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5050 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5070 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5080 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5090 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5110 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5120 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5130 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5140 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5150 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5160 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5190 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5210 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5220 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5230 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5240 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5270 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5290 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5320 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5330 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5350 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5390 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5400 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5410 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5420 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5430 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5440 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5490 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5500 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5510 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5520 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5530 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5540 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5560 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5570 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5580 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5610 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5620 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5630 Reward: 1.0 Steps Taken: 13 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5660 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5690 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5720 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5730 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5770 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5780 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5790 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5810 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5820 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5830 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5860 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5870 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5880 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5890 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5920 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5930 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5950 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5960 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5990 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6010 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6020 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6040 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6070 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6080 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6090 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6110 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6120 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6130 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6140 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6150 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6160 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6190 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6210 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6220 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6230 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6240 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6260 Reward: 1.0 Steps Taken: 11 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6270 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6290 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6300 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6320 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6330 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6390 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6410 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6430 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6440 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6490 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6500 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6520 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6530 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6540 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6560 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6570 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6650 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6690 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 6700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6710 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6720 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6730 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6760 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6770 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6780 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6790 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6800 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6810 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6860 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6870 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6890 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6900 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6910 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6920 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6930 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6950 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6990 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7010 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7020 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7030 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7040 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7050 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7070 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7080 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7090 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7100 Reward: 1.0 Steps Taken: 11 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7110 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7120 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7130 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7140 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7150 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7160 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7170 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7180 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7190 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7210 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7220 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7230 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7240 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7260 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7270 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7290 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7310 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7320 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7330 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7390 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7410 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7420 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7430 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7440 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7490 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7500 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7510 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7520 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7540 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7560 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7580 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7600 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7630 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 7660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7690 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7720 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7730 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7770 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7780 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7790 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7810 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7830 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7850 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7860 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7870 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7920 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7950 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7960 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7980 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8010 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8020 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8040 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8070 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8080 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8090 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8110 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8120 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8130 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8140 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8150 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8160 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8170 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8180 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8190 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8200 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8210 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8220 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8230 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8240 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8250 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8270 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8280 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8290 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8310 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8320 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8330 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8360 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8390 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8410 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8430 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8440 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8470 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8490 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8500 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8520 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8540 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8550 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8560 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8590 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8610 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8660 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 8670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8690 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8700 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8720 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8730 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8770 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8780 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8790 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8800 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8810 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8820 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8860 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8870 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8920 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8940 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8950 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9010 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9020 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9040 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9070 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9080 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9090 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9110 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9120 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9130 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9140 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9150 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9160 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9190 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9210 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9220 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9230 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9240 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9270 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9290 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9310 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9320 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9330 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9350 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9370 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9390 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9410 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9430 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9440 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9480 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9490 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9500 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9520 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9540 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9560 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9630 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9640 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 9650 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9660 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9670 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9680 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9690 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9700 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9720 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9730 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9750 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9760 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9770 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9780 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9790 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9810 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9830 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9860 Reward: 1.0 Steps Taken: 12 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9870 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9890 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9920 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9950 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9960 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    }
   ],
   "source": [
    "# for i_episode in range(num_episodes):\n",
    "    \n",
    "#     # resets the environment\n",
    "#     state = env.reset()\n",
    "#     step = 0\n",
    "#     #reward = 0\n",
    "\n",
    "#   ## as epsilon decays with more timesteps, the prob. of selecting a random val < e decays --> more likely to exploit. \n",
    "#     if epsilon > epsilon_final:\n",
    "#             epsilon *= epsilon_decay\n",
    "\n",
    "#     while True:\n",
    "        \n",
    "#         step += 1\n",
    "        \n",
    "#         random_for_epsilon = np.random.rand()\n",
    "#         if random_for_epsilon <= epsilon:\n",
    "#           action = env.action_space.sample()\n",
    "#         else: \n",
    "#           action = np.argmax(Q.loc[state])\n",
    "  \n",
    "         \n",
    "#         ## env gives reward and next state and whether we've reached terminal state upon taking action at current state.. \n",
    "#         new_state, reward , done, info = env.step(action)\n",
    "\n",
    "#         ##if you want reward penalized at for each timestep\n",
    "#         #reward = rewarder(new_state, reward)\n",
    "\n",
    "#         # filling the Q Table - \n",
    "        \n",
    "#         Q.loc[state, action] = (1- learning_rate)*Q.at[state, action] + learning_rate*(reward + gamma * np.max(Q.loc[new_state]))\n",
    "        \n",
    "#         # Setting new state for next action\n",
    "#         state = new_state\n",
    "#         tile = og_4x4[rowsandcols(state)[0]][rowsandcols(state)[1]]\n",
    "#         #env.render()\n",
    "        \n",
    "#         if done:\n",
    "#           #print(Q)\n",
    "          \n",
    "#           terminal_state.append(tile)\n",
    "#           steps_total.append(step)\n",
    "#           rewards_total.append(reward)\n",
    "#           epsilon_total.append(epsilon)\n",
    "#           if i_episode % 10 == 0:\n",
    "#             print('Episode: {} Reward: {} Steps Taken: {} Terminal State: {}, Epsilon: {}'.format(i_episode,reward, step, tile, epsilon))\n",
    "#           break\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "collapsed": true,
    "id": "YfFp3Hl7EfZF",
    "outputId": "3db8423f-28d2-4a83-d60d-9e5502b8f338"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.531441</td>\n",
       "      <td>0.590490</td>\n",
       "      <td>0.478297</td>\n",
       "      <td>0.531441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.531441</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.430467</td>\n",
       "      <td>0.478297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.478297</td>\n",
       "      <td>0.387407</td>\n",
       "      <td>0.313935</td>\n",
       "      <td>0.430466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.426170</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.590490</td>\n",
       "      <td>0.656100</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.531441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.430467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.000331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.656100</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.729000</td>\n",
       "      <td>0.590490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.656100</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.000876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.729000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.729000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.729000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3\n",
       "0   0.531441  0.590490  0.478297  0.531441\n",
       "1   0.531441  0.000876  0.430467  0.478297\n",
       "2   0.478297  0.387407  0.313935  0.430466\n",
       "3   0.426170  0.000737  0.000675  0.000682\n",
       "4   0.590490  0.656100  0.000876  0.531441\n",
       "5   0.000332  0.000900  0.000743  0.000973\n",
       "6   0.000876  0.810000  0.000738  0.430467\n",
       "7   0.000090  0.000415  0.000820  0.000331\n",
       "8   0.656100  0.000653  0.729000  0.590490\n",
       "9   0.656100  0.810000  0.810000  0.000876\n",
       "10  0.729000  0.900000  0.000774  0.729000\n",
       "11  0.000755  0.000009  0.000059  0.000860\n",
       "12  0.000137  0.000079  0.000294  0.000726\n",
       "13  0.000653  0.810000  0.900000  0.729000\n",
       "14  0.810000  0.900000  1.000000  0.810000\n",
       "15  0.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'reward')"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def movmean(sig, wind = 10):\n",
    "    av_sig = [np.mean(sig[i-int(wind/2) : i+int(wind/2)]) for i in np.arange(len(sig)-wind)+int(wind/2)+1]\n",
    "    return av_sig\n",
    "    \n",
    "fig, ax = plt.subplots(1,2,sharex = True,figsize = (18,5))\n",
    "ax[0].plot(movmean(steps_total,50)); ax[0].set_title('# of steps'); ax[0].set_xlabel('# episode'); ax[0].set_ylabel('# steps')\n",
    "ax[1].plot(movmean(rewards_total,50)); ax[1].set_title('Total reward'); ax[1].set_xlabel('# episode'); ax[1].set_ylabel('reward')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b074fd5f48>]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([np.mean(rewards_total[i:i+10]) for i in range(len(rewards_total)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "UN_tSzGpScxG"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "NM5W4AlyTapL",
    "outputId": "71ec46db-d0cd-4a80-cffe-4145d0cdf630"
   },
   "outputs": [],
   "source": [
    "# plt.axhline(y=6, color='green', linestyle='-')\n",
    "# plt.bar(np.arange(0, 1000), steps_total, \n",
    "#         width = 0.4, color = 'blue')\n",
    "# plt.xlabel('episode index')\n",
    "# plt.ylabel('number of steps taken')\n",
    "# plt.title(' Restricted 4x4 Negative Rewards')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "LsbOjyv7O5l7",
    "outputId": "9aa7f9ba-087b-44b7-a8c3-997082f5138c"
   },
   "outputs": [],
   "source": [
    "# plt.scatter(np.arange(0, 1000), rewards_total, s = 0.5, color = 'blue')\n",
    "# plt.title('Restricted 4x4 Negative Rewards')\n",
    "# plt.xlabel('episode')\n",
    "# plt.ylabel('reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 Reward: 0.0 Steps Taken: 10 Terminal State: H, Epsilon: 0.8991\n",
      "Episode: 10 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.8901493517965845\n",
      "Episode: 20 Reward: 0.0 Steps Taken: 14 Terminal State: H, Epsilon: 0.8812878083682346\n",
      "Episode: 30 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.8725144826662403\n",
      "Episode: 40 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.8638284964725682\n",
      "Episode: 50 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.8552289803119505\n",
      "Episode: 60 Reward: 0.0 Steps Taken: 10 Terminal State: H, Epsilon: 0.8467150733648501\n",
      "Episode: 70 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.8382859233812912\n",
      "Episode: 80 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.8299406865955485\n",
      "Episode: 90 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.8216785276416861\n",
      "Episode: 100 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.8134986194699355\n",
      "Episode: 110 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.8054001432639079\n",
      "Episode: 120 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.7973822883586298\n",
      "Episode: 130 Reward: 0.0 Steps Taken: 16 Terminal State: H, Epsilon: 0.7894442521593946\n",
      "Episode: 140 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.7815852400614219\n",
      "Episode: 150 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.7738044653703178\n",
      "Episode: 160 Reward: 0.0 Steps Taken: 12 Terminal State: H, Epsilon: 0.7661011492233244\n",
      "Episode: 170 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.7584745205113566\n",
      "Episode: 180 Reward: 0.0 Steps Taken: 10 Terminal State: H, Epsilon: 0.7509238158018122\n",
      "Episode: 190 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.7434482792621522\n",
      "Episode: 200 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.7360471625842407\n",
      "Episode: 210 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.7287197249094396\n",
      "Episode: 220 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.7214652327544469\n",
      "Episode: 230 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.7142829599378745\n",
      "Episode: 240 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.7071721875075574\n",
      "Episode: 250 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.7001322036685851\n",
      "Episode: 260 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.6931623037120513\n",
      "Episode: 270 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.686261789944511\n",
      "Episode: 280 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.6794299716181409\n",
      "Episode: 290 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.6726661648615948\n",
      "Episode: 300 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.6659696926115485\n",
      "Episode: 310 Reward: 0.0 Steps Taken: 11 Terminal State: H, Epsilon: 0.6593398845449232\n",
      "Episode: 320 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.6527760770117879\n",
      "Episode: 330 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.6462776129689248\n",
      "Episode: 340 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.6398438419140611\n",
      "Episode: 350 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.6334741198207515\n",
      "Episode: 360 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.6271678090739116\n",
      "Episode: 370 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.6209242784059908\n",
      "Episode: 380 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.6147429028337835\n",
      "Episode: 390 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.608623063595866\n",
      "Episode: 400 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.6025641480906593\n",
      "Episode: 410 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.5965655498151058\n",
      "Episode: 420 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.590626668303959\n",
      "Episode: 430 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.5847469090696757\n",
      "Episode: 440 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.5789256835429077\n",
      "Episode: 450 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.5731624090135847\n",
      "Episode: 460 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.5674565085725853\n",
      "Episode: 470 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.5618074110539871\n",
      "Episode: 480 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.5562145509778935\n",
      "Episode: 490 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.5506773684938275\n",
      "Episode: 500 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.545195309324691\n",
      "Episode: 510 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.5397678247112803\n",
      "Episode: 520 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.5343943713573559\n",
      "Episode: 530 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.5290744113752571\n",
      "Episode: 540 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.5238074122320594\n",
      "Episode: 550 Reward: 0.0 Steps Taken: 12 Terminal State: H, Epsilon: 0.5185928466962675\n",
      "Episode: 560 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.5134301927850384\n",
      "Episode: 570 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.5083189337119314\n",
      "Episode: 580 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.5032585578351761\n",
      "Episode: 590 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.4982485586064576\n",
      "Episode: 600 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.49328843452021\n",
      "Episode: 610 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.4883776890634155\n",
      "Episode: 620 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.48351583066590287\n",
      "Episode: 630 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.4787023726511407\n",
      "Episode: 640 Reward: 0.0 Steps Taken: 10 Terminal State: H, Epsilon: 0.4739368331875209\n",
      "Episode: 650 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.46921873524012647\n",
      "Episode: 660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.46454760652298055\n",
      "Episode: 670 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.4599229794517696\n",
      "Episode: 680 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.4553443910970378\n",
      "Episode: 690 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.4508113831378475\n",
      "Episode: 700 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.44632350181590114\n",
      "Episode: 710 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.4418802978901191\n",
      "Episode: 720 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.4374813265916708\n",
      "Episode: 730 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.43312614757945245\n",
      "Episode: 740 Reward: 0.0 Steps Taken: 11 Terminal State: H, Epsilon: 0.4288143248960088\n",
      "Episode: 750 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.4245454269238931\n",
      "Episode: 760 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.42031902634246215\n",
      "Episode: 770 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.4161347000851009\n",
      "Episode: 780 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.41199202929687323\n",
      "Episode: 790 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.40789059929259386\n",
      "Episode: 800 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.4038299995153185\n",
      "Episode: 810 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.3998098234952461\n",
      "Episode: 820 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.3958296688090315\n",
      "Episode: 830 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.3918891370395019\n",
      "Episode: 840 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.3879878337357753\n",
      "Episode: 850 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.3841253683737753\n",
      "Episode: 860 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.38030135431713974\n",
      "Episode: 870 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.37651540877851764\n",
      "Episode: 880 Reward: 0.0 Steps Taken: 10 Terminal State: H, Epsilon: 0.3727671527812518\n",
      "Episode: 890 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.3690562111214433\n",
      "Episode: 900 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.3653822123303929\n",
      "Episode: 910 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.36174478863741666\n",
      "Episode: 920 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.3581435759330318\n",
      "Episode: 930 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.3545782137325093\n",
      "Episode: 940 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.3510483451397886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 950 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.3475536168117524\n",
      "Episode: 960 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.344093678922856\n",
      "Episode: 970 Reward: 0.0 Steps Taken: 13 Terminal State: H, Epsilon: 0.3406681851301106\n",
      "Episode: 980 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.33727679253841275\n",
      "Episode: 990 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.33391916166622093\n",
      "Episode: 1000 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.33059495641157327\n",
      "Episode: 1010 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.327303844018443\n",
      "Episode: 1020 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.32404549504342933\n",
      "Episode: 1030 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.3208195833227805\n",
      "Episode: 1040 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.3176257859397435\n",
      "Episode: 1050 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.31446378319224055\n",
      "Episode: 1060 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.3113332585608661\n",
      "Episode: 1070 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.30823389867720324\n",
      "Episode: 1080 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.30516539329245534\n",
      "Episode: 1090 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.30212743524638963\n",
      "Episode: 1100 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.29911972043659035\n",
      "Episode: 1110 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.29614194778801745\n",
      "Episode: 1120 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.2931938192228692\n",
      "Episode: 1130 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.2902750396307441\n",
      "Episode: 1140 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.2873853168390999\n",
      "Episode: 1150 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.28452436158400723\n",
      "Episode: 1160 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.28169188748119345\n",
      "Episode: 1170 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.2788876109973761\n",
      "Episode: 1180 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.27611125142188003\n",
      "Episode: 1190 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.2733625308385389\n",
      "Episode: 1200 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.27064117409787486\n",
      "Episode: 1210 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.2679469087895562\n",
      "Episode: 1220 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.2652794652151285\n",
      "Episode: 1230 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.26263857636101795\n",
      "Episode: 1240 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.2600239778718029\n",
      "Episode: 1250 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.2574354080237513\n",
      "Episode: 1260 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.25487260769862247\n",
      "Episode: 1270 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.2523353203577288\n",
      "Episode: 1280 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.2498232920162562\n",
      "Episode: 1290 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.24733627121783933\n",
      "Episode: 1300 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.24487400900939155\n",
      "Episode: 1310 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.24243625891618384\n",
      "Episode: 1320 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.2400227769171727\n",
      "Episode: 1330 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.23763332142057336\n",
      "Episode: 1340 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.23526765323967616\n",
      "Episode: 1350 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.2329255355689038\n",
      "Episode: 1360 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.2306067339601068\n",
      "Episode: 1370 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.22831101629909523\n",
      "Episode: 1380 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.2260381527824036\n",
      "Episode: 1390 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.22378791589428754\n",
      "Episode: 1400 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.22156008038394912\n",
      "Episode: 1410 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.21935442324298907\n",
      "Episode: 1420 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.2171707236830835\n",
      "Episode: 1430 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.21500876311388276\n",
      "Episode: 1440 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.21286832512113016\n",
      "Episode: 1450 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.21074919544499907\n",
      "Episode: 1460 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.20865116195864492\n",
      "Episode: 1470 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.20657401464697137\n",
      "Episode: 1480 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.20451754558560759\n",
      "Episode: 1490 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.20248154892009457\n",
      "Episode: 1500 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.2004658208452793\n",
      "Episode: 1510 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.19847015958491335\n",
      "Episode: 1520 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.19649436537145518\n",
      "Episode: 1530 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.19453824042607284\n",
      "Episode: 1540 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.19260158893884646\n",
      "Episode: 1550 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.19068421704916744\n",
      "Episode: 1560 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.18878593282633258\n",
      "Episode: 1570 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.18690654625033198\n",
      "Episode: 1580 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.18504586919282773\n",
      "Episode: 1590 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.18320371539832184\n",
      "Episode: 1600 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.1813799004655124\n",
      "Episode: 1610 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.17957424182883425\n",
      "Episode: 1620 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.1777865587401846\n",
      "Episode: 1630 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.17601667225082937\n",
      "Episode: 1640 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.17426440519349085\n",
      "Episode: 1650 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.17252958216461264\n",
      "Episode: 1660 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.1708120295068018\n",
      "Episode: 1670 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.16911157529144558\n",
      "Episode: 1680 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.16742804930150101\n",
      "Episode: 1690 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.1657612830144564\n",
      "Episode: 1700 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.16411110958546163\n",
      "Episode: 1710 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.16247736383062722\n",
      "Episode: 1720 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.16085988221048902\n",
      "Episode: 1730 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.1592585028136378\n",
      "Episode: 1740 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.1576730653405119\n",
      "Episode: 1750 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.15610341108735093\n",
      "Episode: 1760 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.15454938293030945\n",
      "Episode: 1770 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.15301082530972876\n",
      "Episode: 1780 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.15148758421456512\n",
      "Episode: 1790 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.14997950716697328\n",
      "Episode: 1800 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.14848644320704313\n",
      "Episode: 1810 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.14700824287768857\n",
      "Episode: 1820 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.14554475820968676\n",
      "Episode: 1830 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.1440958427068661\n",
      "Episode: 1840 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.14266135133144195\n",
      "Episode: 1850 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.1412411404894982\n",
      "Episode: 1860 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.13983506801661344\n",
      "Episode: 1870 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.13844299316363007\n",
      "Episode: 1880 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.1370647765825651\n",
      "Episode: 1890 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.13570028031266154\n",
      "Episode: 1900 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.13434936776657827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1910 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.13301190371671742\n",
      "Episode: 1920 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.13168775428168805\n",
      "Episode: 1930 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.13037678691290464\n",
      "Episode: 1940 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.12907887038131852\n",
      "Episode: 1950 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.1277938747642821\n",
      "Episode: 1960 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.12652167143254323\n",
      "Episode: 1970 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.12526213303736936\n",
      "Episode: 1980 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.1240151334977999\n",
      "Episode: 1990 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.12278054798802522\n",
      "Episode: 2000 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.12155825292489168\n",
      "Episode: 2010 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.12034812595553068\n",
      "Episode: 2020 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.11915004594511107\n",
      "Episode: 2030 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.11796389296471349\n",
      "Episode: 2040 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.11678954827932533\n",
      "Episode: 2050 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.11562689433595524\n",
      "Episode: 2060 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.11447581475186601\n",
      "Episode: 2070 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.11333619430292452\n",
      "Episode: 2080 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.11220791891206763\n",
      "Episode: 2090 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.11109087563788311\n",
      "Episode: 2100 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.109984952663304\n",
      "Episode: 2110 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.10889003928441565\n",
      "Episode: 2120 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.10780602589937407\n",
      "Episode: 2130 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.10673280399743483\n",
      "Episode: 2140 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.1056702661480909\n",
      "Episode: 2150 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.10461830599031888\n",
      "Episode: 2160 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.10357681822193202\n",
      "Episode: 2170 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.10254569858903956\n",
      "Episode: 2180 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.10152484387561062\n",
      "Episode: 2190 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.1005141518931423\n",
      "Episode: 2200 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2210 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2220 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2230 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2240 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2250 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2260 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2270 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2280 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2290 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2300 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2310 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2320 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2330 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2340 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2350 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2360 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2370 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2380 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2390 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2400 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2410 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2420 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2430 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2440 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2450 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2460 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2470 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2480 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2490 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2500 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2510 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2520 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09991257268528593\n",
      "Episode: 2540 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2550 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2560 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2570 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2580 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2590 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2600 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2610 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2620 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2630 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2640 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2650 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2660 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2670 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2680 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2690 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2700 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2710 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2720 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2730 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2740 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2750 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2760 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2770 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2780 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2790 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2800 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2810 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2820 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2830 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2840 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2850 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2860 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2870 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2880 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2890 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2900 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2910 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2920 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2930 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2940 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2950 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2960 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2970 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2980 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 2990 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3000 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3010 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3020 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3030 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3040 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3050 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3060 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3070 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3080 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3090 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3100 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3110 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3120 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3130 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3140 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3150 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3160 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3170 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3180 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3190 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3200 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3210 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3220 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3230 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3240 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3250 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3260 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3270 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3280 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3290 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3300 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3310 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3320 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3330 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3340 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3350 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3360 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3370 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3380 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3390 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3400 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3410 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3420 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3430 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3440 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3450 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3460 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3470 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3480 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3490 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3500 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3510 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3520 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3530 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3540 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3550 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3560 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3570 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3580 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3590 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3600 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3610 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3620 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3630 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3640 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3650 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3660 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3670 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3680 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3690 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3700 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3710 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3720 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3730 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3740 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3750 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3760 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3770 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3780 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3790 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3800 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3810 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3820 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3830 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3840 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3850 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3860 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3870 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3880 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3890 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3900 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3910 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3920 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3930 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3940 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3950 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3960 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3970 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3980 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 3990 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4000 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4010 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4020 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4030 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4040 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4050 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4060 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4070 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4080 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4090 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4100 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4110 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4120 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4130 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4140 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4150 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4160 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4170 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4180 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4190 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4200 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4210 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4220 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4230 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4240 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4250 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4260 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4270 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4280 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4290 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4300 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4310 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4320 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4330 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4340 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4350 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4360 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4370 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4380 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4390 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4400 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4410 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4420 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4430 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4440 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4450 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4460 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4470 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4480 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4490 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4500 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4510 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4520 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4530 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4540 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4550 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4560 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4570 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4580 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4590 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4600 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4610 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4620 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4630 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4640 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4650 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4660 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4670 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4680 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4690 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4700 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4710 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4720 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4730 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4740 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4750 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4760 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4770 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4780 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4790 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4800 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4810 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4820 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4830 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4840 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4850 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4860 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4870 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4880 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4890 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4900 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4910 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4920 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4930 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4940 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4950 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4960 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4970 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4980 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 4990 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5000 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5010 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5020 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5030 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5040 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5050 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5060 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5070 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5080 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5090 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5100 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5110 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5120 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5130 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5140 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5150 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5160 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5170 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5180 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5190 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5200 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5210 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5220 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5230 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5240 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5250 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5260 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5270 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5280 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5290 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5300 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5310 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5320 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5330 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5340 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5350 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5360 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5370 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5380 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5390 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5400 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5410 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5420 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5430 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5440 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5450 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5460 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5470 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5480 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5490 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5500 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5510 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5520 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5530 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5540 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5550 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5560 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5570 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5580 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5590 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5600 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5610 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5620 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5630 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5640 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5650 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5660 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5670 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5680 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5690 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5700 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5710 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5720 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5730 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5740 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5750 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5760 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5770 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5780 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5790 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5800 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5810 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5820 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5830 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5840 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5850 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5860 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5870 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5880 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5890 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5900 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5910 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5920 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5930 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5940 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5950 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5960 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5970 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5980 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 5990 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6000 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6010 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6020 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6030 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6040 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6050 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6060 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6070 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6080 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6090 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6100 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6110 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6120 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6130 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6140 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6150 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6160 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6170 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6180 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6190 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6200 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6210 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6220 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6230 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6240 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6250 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6260 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6270 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6280 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6290 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6300 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6310 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6320 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6330 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6340 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6350 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6360 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6370 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6380 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6390 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6400 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6410 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6420 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6430 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6440 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6450 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6460 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6470 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6480 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6490 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6500 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6510 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6520 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6530 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6540 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6550 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6560 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6570 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6580 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6590 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6600 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6610 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6620 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6630 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6640 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6650 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6660 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6670 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6680 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6690 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6700 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6710 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6720 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6730 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6740 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6750 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6760 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 6770 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6780 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6790 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6800 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6810 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6820 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6830 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6840 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6850 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6860 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6870 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6880 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6890 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6900 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6910 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6920 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6930 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6940 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6950 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6960 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6970 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6980 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 6990 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7000 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7010 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7020 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7030 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7040 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7050 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7060 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7070 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7080 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7090 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7100 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7110 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7120 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7130 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7140 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7150 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7160 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7170 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7180 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7190 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7200 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7210 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7220 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7230 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7240 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7250 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7260 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7270 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7280 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7290 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7300 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7310 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7320 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7330 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7340 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7350 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7360 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7370 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7380 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7390 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7400 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7410 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7420 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7430 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7440 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7450 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7460 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7470 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7480 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7490 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7500 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7510 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7520 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7530 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7540 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7550 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7560 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7570 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7580 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7590 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7600 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7610 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7620 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7630 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7640 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7650 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7660 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7670 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7680 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7690 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7700 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7710 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7720 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7730 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7740 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7750 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7760 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7770 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 7780 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7790 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7800 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7810 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7820 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7830 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7840 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7850 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7860 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7870 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7880 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7890 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7900 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7910 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7920 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7930 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7940 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7950 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7960 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7970 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7980 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 7990 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8000 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8010 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8020 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8030 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8040 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8050 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8060 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8070 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8080 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8090 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8100 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8110 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8120 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8130 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8140 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8150 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8160 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8170 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8180 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8190 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8200 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8210 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8220 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8230 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8240 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8250 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8260 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8270 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8280 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8290 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8300 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8310 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8320 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8330 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8340 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8350 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8360 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8370 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8380 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8390 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8400 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8410 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8420 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8430 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8440 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8450 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8460 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8470 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8480 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8490 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8500 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8510 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8520 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8530 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8540 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8550 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8560 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8570 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8580 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8590 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8600 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8610 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8620 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8630 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8640 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8650 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8660 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8670 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8680 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8690 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8700 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8710 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8720 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 8730 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8740 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8750 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8760 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8770 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8780 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8790 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8800 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8810 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8820 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8830 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8840 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8850 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8860 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8870 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8880 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8890 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8900 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8910 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8920 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8930 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8940 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8950 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8960 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8970 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8980 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 8990 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9000 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9010 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9020 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9030 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9040 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9050 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9060 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9070 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9080 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9090 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9100 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9110 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9120 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9130 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9140 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9150 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9160 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9170 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9180 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9190 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9200 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9210 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9220 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9230 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9240 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9250 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9260 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9270 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9280 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9290 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9300 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9310 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9320 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9330 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9340 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9350 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9360 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9370 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9380 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9390 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9400 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9410 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9420 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9430 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9440 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9450 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9460 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9470 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9480 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9490 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9500 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9510 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9520 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9530 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9540 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9550 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9560 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9570 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9580 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9590 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9600 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9610 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9620 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9630 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9640 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9650 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9660 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9670 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9680 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9690 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 9700 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9710 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9720 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9730 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9740 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9750 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9760 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9770 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9780 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9790 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9800 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9810 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9820 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9830 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9840 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9850 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9860 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9870 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9880 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9890 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9900 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9910 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9920 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9930 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9940 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9950 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9960 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9970 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9980 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n",
      "Episode: 9990 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09991257268528593\n"
     ]
    }
   ],
   "source": [
    "# Training again based on previous Q table - noisy environment (flipped locations)\n",
    "Q_copy = Q.copy()\n",
    "#Q_copy = pd.DataFrame(np.random.rand(n_states,n_actions)/1000)\n",
    "#Q_copy.loc[15] = np.zeros(n_actions,)\n",
    "#Q = restrict_actions(Q, n_states, n_rows)\n",
    "\n",
    "env_inv = gym.make('FrozenLake-v1', is_slippery=False, desc = og_4x4_inv)\n",
    "\n",
    "env_inv.reset()\n",
    "# visualize 4x4 frozen lake\n",
    "env_inv.render()\n",
    "epsilon = 0.99#0.8\n",
    "#epsilon = 0.2\n",
    "epsilon_final = 0.1\n",
    "epsilon_decay = 0.999\n",
    "gamma = 0.90 # discount factor\n",
    "learning_rate = 0.9 #how important is the difference between q-val from q-table and what's observed\n",
    "num_episodes = 10000\n",
    "\n",
    "\n",
    "terminal_state_inv, steps_total_inv, rewards_total_inv, epsilon_total_inv, Q = train_model(Q_copy,env_inv,num_episodes,  epsilon_final, epsilon , epsilon_decay ,  learning_rate,  gamma  )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.7992\n",
      "Episode: 10 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.7912438682636309\n",
      "Episode: 20 Reward: 0.0 Steps Taken: 19 Terminal State: H, Epsilon: 0.7833669407717642\n",
      "Episode: 30 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.7755684290366581\n",
      "Episode: 40 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.7678475524200608\n",
      "Episode: 50 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.7602035380550674\n",
      "Episode: 60 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.7526356207687559\n",
      "Episode: 70 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.7451430430055925\n",
      "Episode: 80 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.7377250547515992\n",
      "Episode: 90 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.7303809134592769\n",
      "Episode: 100 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.7231098839732764\n",
      "Episode: 110 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.7159112384568073\n",
      "Episode: 120 Reward: 0.0 Steps Taken: 17 Terminal State: H, Epsilon: 0.7087842563187822\n",
      "Episode: 130 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.7017282241416841\n",
      "Episode: 140 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.694742435610153\n",
      "Episode: 150 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.6878261914402828\n",
      "Episode: 160 Reward: 0.0 Steps Taken: 17 Terminal State: H, Epsilon: 0.6809787993096221\n",
      "Episode: 170 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.6741995737878729\n",
      "Episode: 180 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.6674878362682779\n",
      "Episode: 190 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.6608429148996913\n",
      "Episode: 200 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.6542641445193258\n",
      "Episode: 210 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.6477508665861693\n",
      "Episode: 220 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.6413024291150646\n",
      "Episode: 230 Reward: 0.0 Steps Taken: 11 Terminal State: H, Epsilon: 0.6349181866114447\n",
      "Episode: 240 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.6285975000067183\n",
      "Episode: 250 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.6223397365942986\n",
      "Episode: 260 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.6161442699662687\n",
      "Episode: 270 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.6100104799506774\n",
      "Episode: 280 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.6039377525494594\n",
      "Episode: 290 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.5979254798769741\n",
      "Episode: 300 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.5919730600991551\n",
      "Episode: 310 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.5860798973732659\n",
      "Episode: 320 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.5802454017882566\n",
      "Episode: 330 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.5744689893057117\n",
      "Episode: 340 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.5687500817013885\n",
      "Episode: 350 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.5630881065073355\n",
      "Episode: 360 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.557482496954589\n",
      "Episode: 370 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.5519326919164373\n",
      "Episode: 380 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.5464381358522531\n",
      "Episode: 390 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.5409982787518822\n",
      "Episode: 400 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.5356125760805872\n",
      "Episode: 410 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.5302804887245397\n",
      "Episode: 420 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.5250014829368536\n",
      "Episode: 430 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.5197750302841573\n",
      "Episode: 440 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.5146006075936969\n",
      "Episode: 450 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.5094776969009654\n",
      "Episode: 460 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.5044057853978547\n",
      "Episode: 470 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.49938436538132314\n",
      "Episode: 480 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.4944129342025731\n",
      "Episode: 490 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.48949099421673664\n",
      "Episode: 500 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.48461805273305963\n",
      "Episode: 510 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.47979362196558345\n",
      "Episode: 520 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.4750172189843173\n",
      "Episode: 530 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.47028836566689614\n",
      "Episode: 540 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.46560658865072047\n",
      "Episode: 550 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.460971419285572\n",
      "Episode: 560 Reward: 0.0 Steps Taken: 10 Terminal State: H, Epsilon: 0.4563823935867017\n",
      "Episode: 570 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.45183905218838427\n",
      "Episode: 580 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.44734094029793514\n",
      "Episode: 590 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.4428876076501854\n",
      "Episode: 600 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.4384786084624098\n",
      "Episode: 610 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.4341135013897036\n",
      "Episode: 620 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.4297918494808035\n",
      "Episode: 630 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.4255132201343483\n",
      "Episode: 640 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.42127718505557504\n",
      "Episode: 650 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.41708332021344663\n",
      "Episode: 660 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.4129312057982058\n",
      "Episode: 670 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.4088204261793515\n",
      "Episode: 680 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.40475056986403424\n",
      "Episode: 690 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.4007212294558651\n",
      "Episode: 700 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.3967320016141349\n",
      "Episode: 710 Reward: 0.0 Steps Taken: 10 Terminal State: H, Epsilon: 0.3927824870134399\n",
      "Episode: 720 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.38887229030370796\n",
      "Episode: 730 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.385001020070625\n",
      "Episode: 740 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.3811682887964528\n",
      "Episode: 750 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.37737371282123877\n",
      "Episode: 760 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.3736169123044112\n",
      "Episode: 770 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.36989751118675673\n",
      "Episode: 780 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.36621513715277654\n",
      "Episode: 790 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.36256942159341715\n",
      "Episode: 800 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.3589599995691724\n",
      "Episode: 810 Reward: 1.0 Steps Taken: 12 Terminal State: G, Epsilon: 0.3553865097735525\n",
      "Episode: 820 Reward: 1.0 Steps Taken: 13 Terminal State: G, Epsilon: 0.3518485944969173\n",
      "Episode: 830 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.34834589959066875\n",
      "Episode: 840 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.34487807443180063\n",
      "Episode: 850 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.3414447718878007\n",
      "Episode: 860 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.33804564828190237\n",
      "Episode: 870 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.33468036335868273\n",
      "Episode: 880 Reward: 0.0 Steps Taken: 19 Terminal State: H, Epsilon: 0.3313485802500021\n",
      "Episode: 890 Reward: 1.0 Steps Taken: 11 Terminal State: G, Epsilon: 0.3280499654412834\n",
      "Episode: 900 Reward: 1.0 Steps Taken: 17 Terminal State: G, Epsilon: 0.32478418873812753\n",
      "Episode: 910 Reward: 1.0 Steps Taken: 12 Terminal State: G, Epsilon: 0.32155092323325973\n",
      "Episode: 920 Reward: 0.0 Steps Taken: 3 Terminal State: H, Epsilon: 0.3183498452738065\n",
      "Episode: 930 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.3151806344288976\n",
      "Episode: 940 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.31204297345759036\n",
      "Episode: 950 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.3089365482771137\n",
      "Episode: 960 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.30586104793142815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.30281616456009885\n",
      "Episode: 980 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.29980159336747847\n",
      "Episode: 990 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.29681703259219694\n",
      "Episode: 1000 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.2938621834769546\n",
      "Episode: 1010 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.2909367502386166\n",
      "Episode: 1020 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.28804044003860463\n",
      "Episode: 1030 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.28517296295358346\n",
      "Episode: 1040 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.28233403194643947\n",
      "Episode: 1050 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.27952336283754786\n",
      "Episode: 1060 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.2767406742763261\n",
      "Episode: 1070 Reward: 1.0 Steps Taken: 14 Terminal State: G, Epsilon: 0.27398568771307025\n",
      "Episode: 1080 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.2712581273710722\n",
      "Episode: 1090 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.2685577202190138\n",
      "Episode: 1100 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.26588419594363666\n",
      "Episode: 1110 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.263237286922683\n",
      "Episode: 1120 Reward: 0.0 Steps Taken: 11 Terminal State: H, Epsilon: 0.2606167281981068\n",
      "Episode: 1130 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.25802225744955115\n",
      "Episode: 1140 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.25545361496808977\n",
      "Episode: 1150 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.2529105436302295\n",
      "Episode: 1160 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.2503927888721729\n",
      "Episode: 1170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.24790009866433518\n",
      "Episode: 1180 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.2454322234861165\n",
      "Episode: 1190 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.24298891630092442\n",
      "Episode: 1200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.24056993253144524\n",
      "Episode: 1210 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.2381750300351619\n",
      "Episode: 1220 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.23580396908011508\n",
      "Episode: 1230 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.23345651232090572\n",
      "Episode: 1240 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.2311324247749367\n",
      "Episode: 1250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.22883147379889088\n",
      "Episode: 1260 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.22655342906544304\n",
      "Episode: 1270 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.22429806254020423\n",
      "Episode: 1280 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.2220651484588951\n",
      "Episode: 1290 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.21985446330474676\n",
      "Episode: 1300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.2176657857861265\n",
      "Episode: 1310 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.21549889681438633\n",
      "Episode: 1320 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.21335357948193198\n",
      "Episode: 1330 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.21122961904051035\n",
      "Episode: 1340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.2091268028797128\n",
      "Episode: 1350 Reward: 1.0 Steps Taken: 15 Terminal State: G, Epsilon: 0.20704492050569293\n",
      "Episode: 1360 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.20498376352009562\n",
      "Episode: 1370 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.20294312559919642\n",
      "Episode: 1380 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.20092280247324829\n",
      "Episode: 1390 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.198922591906034\n",
      "Episode: 1400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.19694229367462207\n",
      "Episode: 1410 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.19498170954932426\n",
      "Episode: 1420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1930406432738527\n",
      "Episode: 1430 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.19111890054567424\n",
      "Episode: 1440 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.18921628899656084\n",
      "Episode: 1450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.18733261817333322\n",
      "Episode: 1460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1854676995187962\n",
      "Episode: 1470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.18362134635286415\n",
      "Episode: 1480 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.1817933738538741\n",
      "Episode: 1490 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.17998359904008476\n",
      "Episode: 1500 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.1781918407513601\n",
      "Episode: 1510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.17641791963103487\n",
      "Episode: 1520 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.1746616581079609\n",
      "Episode: 1530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.17292288037873216\n",
      "Episode: 1540 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.17120141239008646\n",
      "Episode: 1550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.16949708182148285\n",
      "Episode: 1560 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.16780971806785186\n",
      "Episode: 1570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.16613915222251802\n",
      "Episode: 1580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.16448521706029195\n",
      "Episode: 1590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1628477470207312\n",
      "Episode: 1600 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.16122657819156724\n",
      "Episode: 1610 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.15962154829229783\n",
      "Episode: 1620 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.1580324966579425\n",
      "Episode: 1630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.15645926422296014\n",
      "Episode: 1640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1549016935053259\n",
      "Episode: 1650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.15335962859076752\n",
      "Episode: 1660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.15183291511715788\n",
      "Episode: 1670 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.15032140025906346\n",
      "Episode: 1680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.14882493271244615\n",
      "Episode: 1690 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1473433626795176\n",
      "Episode: 1700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.14587654185374446\n",
      "Episode: 1710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.14442432340500275\n",
      "Episode: 1720 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.14298656196487988\n",
      "Episode: 1730 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.14156311361212323\n",
      "Episode: 1740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.14015383585823352\n",
      "Episode: 1750 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.1387585876332015\n",
      "Episode: 1760 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.13737722927138682\n",
      "Episode: 1770 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.13600962249753726\n",
      "Episode: 1780 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.13465563041294734\n",
      "Episode: 1790 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.13331511748175456\n",
      "Episode: 1800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.13198794951737225\n",
      "Episode: 1810 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.13067399366905708\n",
      "Episode: 1820 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.12937311840861102\n",
      "Episode: 1830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.12808519351721487\n",
      "Episode: 1840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.12681009007239344\n",
      "Episode: 1850 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.12554768043511014\n",
      "Episode: 1860 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.12429783823699037\n",
      "Episode: 1870 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.12306043836767178\n",
      "Episode: 1880 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.1218353569622807\n",
      "Episode: 1890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.12062247138903309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11942166023695906\n",
      "Episode: 1910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1182328033037494\n",
      "Episode: 1920 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11705578158372329\n",
      "Episode: 1930 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.11589047725591577\n",
      "Episode: 1940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11473677367228365\n",
      "Episode: 1950 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11359455534602904\n",
      "Episode: 1960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11246370794003893\n",
      "Episode: 1970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11134411825543995\n",
      "Episode: 1980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.11023567422026707\n",
      "Episode: 1990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.10913826487824516\n",
      "Episode: 2000 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.108051780377682\n",
      "Episode: 2010 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.10697611196047219\n",
      "Episode: 2020 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.1059111519512103\n",
      "Episode: 2030 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.10485679374641242\n",
      "Episode: 2040 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.10381293180384518\n",
      "Episode: 2050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.10277946163196065\n",
      "Episode: 2060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.1017562797794369\n",
      "Episode: 2070 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.10074328382482223\n",
      "Episode: 2080 Reward: 0.0 Steps Taken: 9 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2090 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2100 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2110 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2120 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2130 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2140 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2150 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2160 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2190 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2200 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2210 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2220 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2230 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2240 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2270 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2290 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2320 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2330 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2350 Reward: 0.0 Steps Taken: 8 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2390 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2410 Reward: 1.0 Steps Taken: 12 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2420 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2430 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2440 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2480 Reward: 1.0 Steps Taken: 13 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2490 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2500 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2510 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2520 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2530 Reward: 1.0 Steps Taken: 12 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2540 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2560 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2580 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2640 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2650 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2660 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2690 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2710 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2720 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2730 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2740 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2770 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2780 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2790 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2810 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2860 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2870 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 2880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2890 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2920 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2950 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 2990 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3010 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3020 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3040 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3060 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3070 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3080 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3090 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3100 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3110 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3120 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3130 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3140 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3150 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3160 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3180 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3190 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3200 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3210 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3220 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3230 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3240 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3270 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3280 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3290 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3300 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3320 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3330 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3380 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3390 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3410 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3430 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3440 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3450 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3480 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3490 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3500 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3510 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3520 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3540 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3560 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3580 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3590 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3620 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3670 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3680 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3690 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3700 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3710 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3720 Reward: 1.0 Steps Taken: 11 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3730 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3740 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3750 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3770 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3780 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3790 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3810 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3820 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3860 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3870 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3880 Reward: 1.0 Steps Taken: 11 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3890 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3920 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3940 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3950 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3960 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 3970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 3990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4010 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4020 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4040 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4070 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4080 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4090 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4110 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4120 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4130 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4140 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4150 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4160 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4190 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4210 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4220 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4230 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4240 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4250 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4260 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4270 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4290 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4310 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4320 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4330 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4360 Reward: 1.0 Steps Taken: 14 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4380 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4390 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4410 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4420 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4430 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4440 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4460 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4480 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4490 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4500 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4520 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4530 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4540 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4560 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4580 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4600 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4640 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4660 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4670 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4690 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4720 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4730 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4770 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 4780 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4790 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4810 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4820 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4860 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4870 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4920 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4950 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 4990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5010 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5020 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5040 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5050 Reward: 0.0 Steps Taken: 17 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5070 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5080 Reward: 1.0 Steps Taken: 11 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5090 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5110 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5120 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5130 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5140 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5150 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5160 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5180 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5190 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5210 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5220 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5230 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5240 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5270 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5290 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5310 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5320 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5330 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5340 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5370 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5390 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5410 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5430 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5440 Reward: 1.0 Steps Taken: 12 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5450 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5460 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5490 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5500 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5520 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5540 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5560 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5570 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5590 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5640 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5650 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5680 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5690 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5720 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5730 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5740 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5770 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5780 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5790 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5800 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 5810 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5840 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5850 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5860 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5870 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5900 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5920 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5940 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5950 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 5990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6000 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6010 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6020 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6040 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6070 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6080 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6090 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6110 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6120 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6130 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6140 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6150 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6160 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6170 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6190 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6210 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6220 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6230 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6240 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6260 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6270 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6290 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6320 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6330 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6350 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6380 Reward: 1.0 Steps Taken: 12 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6390 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6410 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6430 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6440 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6460 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6490 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6500 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6510 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6520 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6540 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6550 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6560 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6570 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6580 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6590 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6620 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6670 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 6680 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6690 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6720 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6730 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6770 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 6780 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6790 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6800 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6810 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6840 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6860 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6870 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6880 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6890 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6920 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6940 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6950 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6960 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 6990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7010 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7020 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7030 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7040 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7060 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7070 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7080 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7090 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7110 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7120 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7130 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7140 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7150 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7160 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7190 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7200 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7210 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7220 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7230 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7240 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7260 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7270 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7280 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7290 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7300 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7320 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7330 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7360 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7370 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7380 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7390 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7410 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7430 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7440 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7470 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7480 Reward: 1.0 Steps Taken: 13 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7490 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7500 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7510 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7520 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7540 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7550 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7560 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7570 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7590 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7600 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7610 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7620 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7630 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 7640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7650 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7690 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7700 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7720 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7730 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7750 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7770 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7780 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7790 Reward: 0.0 Steps Taken: 7 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7800 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7810 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7850 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7860 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7870 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7890 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7900 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7910 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7920 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7950 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7960 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 7980 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 7990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8000 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8010 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8020 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8040 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8050 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8070 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8080 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8090 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8110 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8120 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8130 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8140 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8150 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8160 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8170 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8190 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8210 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8220 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8230 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8240 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8260 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8270 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8290 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8320 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8330 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8360 Reward: 0.0 Steps Taken: 6 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8370 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8390 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8400 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8410 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8420 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8430 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8440 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8470 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8490 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8500 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8510 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8520 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8530 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8540 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8550 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8560 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8570 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 8580 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8600 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8620 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8650 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8680 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8690 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8720 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8730 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8750 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8760 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8770 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8780 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8790 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8800 Reward: 0.0 Steps Taken: 10 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8810 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8840 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8860 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8870 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8880 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8900 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8910 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8920 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8940 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8950 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8960 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 8970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8980 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 8990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9000 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9010 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9020 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9030 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9040 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9050 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9060 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9070 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9080 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9090 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9100 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9110 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9120 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9130 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9140 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9150 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9160 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9170 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9180 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9190 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9200 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9210 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9220 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9230 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9240 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9250 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9260 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9270 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9280 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9290 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9300 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9310 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9320 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9330 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9340 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9350 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9360 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9370 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9380 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9390 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9400 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9410 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9420 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9430 Reward: 0.0 Steps Taken: 2 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9440 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9450 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9460 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9470 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9480 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9490 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9500 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9510 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9520 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9530 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9540 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 9550 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9560 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9570 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9580 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9590 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9600 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9610 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9620 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9630 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9640 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9650 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9660 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9670 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9680 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9690 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9700 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9710 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9720 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9730 Reward: 0.0 Steps Taken: 5 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9740 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9750 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9760 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9770 Reward: 0.0 Steps Taken: 4 Terminal State: H, Epsilon: 0.09994015273159322\n",
      "Episode: 9780 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9790 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9800 Reward: 1.0 Steps Taken: 9 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9810 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9820 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9830 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9840 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9850 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9860 Reward: 1.0 Steps Taken: 10 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9870 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9880 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9890 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9900 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9910 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9920 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9930 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9940 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9950 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9960 Reward: 1.0 Steps Taken: 7 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9970 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9980 Reward: 1.0 Steps Taken: 8 Terminal State: G, Epsilon: 0.09994015273159322\n",
      "Episode: 9990 Reward: 1.0 Steps Taken: 6 Terminal State: G, Epsilon: 0.09994015273159322\n"
     ]
    }
   ],
   "source": [
    "# Training again based on previous Q table - noisy environment (flipped locations)\n",
    "Q_copy = Q.copy()\n",
    "Q_copy = pd.DataFrame(np.random.rand(n_states,n_actions)/1000)\n",
    "Q_copy.loc[15] = np.zeros(n_actions,)\n",
    "#Q = restrict_actions(Q, n_states, n_rows)\n",
    "\n",
    "env_inv = gym.make('FrozenLake-v1', is_slippery=False, desc = og_4x4_inv)\n",
    "\n",
    "env_inv.reset()\n",
    "# visualize 4x4 frozen lake\n",
    "env_inv.render()\n",
    "epsilon = 0.8\n",
    "#epsilon = 0.2\n",
    "epsilon_final = 0.1\n",
    "epsilon_decay = 0.999\n",
    "gamma = 0.90 # discount factor\n",
    "learning_rate = 0.9 #how important is the difference between q-val from q-table and what's observed\n",
    "num_episodes = 10000\n",
    "steps_total_inv = [] # store number of steps taken in each episode\n",
    "rewards_total_inv = [] #store reward obtained for each episode\n",
    "epsilon_total_inv = [] #store epsilon obtained at the end of each episode\n",
    "terminal_state_inv = []\n",
    "for i_episode in range(num_episodes):\n",
    "    \n",
    "    # resets the environment\n",
    "    state = env_inv.reset()\n",
    "    step = 0\n",
    "    #reward = 0\n",
    "\n",
    "  ## as epsilon decays with more timesteps, the prob. of selecting a random val < e decays --> more likely to exploit. \n",
    "    if epsilon > epsilon_final:\n",
    "            epsilon *= epsilon_decay\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "        random_for_epsilon = np.random.rand()\n",
    "        if random_for_epsilon <= epsilon:\n",
    "          action = env_inv.action_space.sample()\n",
    "        else: \n",
    "          action = np.argmax(Q_copy.loc[state])\n",
    "  \n",
    "         \n",
    "        ## env gives reward and next state and whether we've reached terminal state upon taking action at current state.. \n",
    "        new_state, reward , done, info = env_inv.step(action)\n",
    "\n",
    "        ##if you want reward penalized at for each timestep\n",
    "        #reward = rewarder(new_state, reward)\n",
    "\n",
    "        # filling the Q Table - \n",
    "        \n",
    "        Q_copy.loc[state, action] = (1- learning_rate)*Q_copy.at[state, action] + learning_rate*(reward + gamma * np.max(Q_copy.loc[new_state]))\n",
    "        \n",
    "        # Setting new state for next action\n",
    "        state = new_state\n",
    "        tile = og_4x4_inv[rowsandcols(state)[0]][rowsandcols(state)[1]]\n",
    "        #env.render()\n",
    "        \n",
    "        if done:\n",
    "          #print(Q)\n",
    "          \n",
    "          terminal_state_inv.append(tile)\n",
    "          steps_total_inv.append(step)\n",
    "          rewards_total_inv.append(reward)\n",
    "          epsilon_total_inv.append(epsilon)\n",
    "          if i_episode % 10 == 0:\n",
    "            print('Episode: {} Reward: {} Steps Taken: {} Terminal State: {}, Epsilon: {}'.format(i_episode,reward, step, tile, epsilon))\n",
    "          break\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'reward')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "   \n",
    "fig, ax = plt.subplots(1,2,sharex = True,figsize = (18,5))\n",
    "ax[0].plot(movmean(steps_total_inv,50)); ax[0].set_title('# of steps'); ax[0].set_xlabel('# episode'); ax[0].set_ylabel('# steps')\n",
    "ax[1].plot(movmean(rewards_total_inv,5)); ax[1].set_title('Total reward'); ax[1].set_xlabel('# episode'); ax[1].set_ylabel('reward')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SFFF', 'FHFH', 'FFFH', 'HFFG'], dtype='<U4')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(og_4x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SFFF', 'FHFH', 'FFFH', 'HFFG'], dtype='<U4')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack(og_4x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dVwtWKmEPT89"
   },
   "outputs": [],
   "source": [
    "## Noisy Secenario (noisy rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## noisy environment (switches between locations over learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## discrete changes in the environments over the iterations ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## 2 transfer learninig and then back to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bigger env that include the former one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## smaller env that is a part of the former one"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Base_4x4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
