{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7A7fa1WMOMwC"
   },
   "source": [
    "# Frozen Lake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPAWi834Wic3"
   },
   "source": [
    "#### Import all requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GutUwuMaOMwE"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eEapxzPbykks"
   },
   "outputs": [],
   "source": [
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h66lZsd0dI_P"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yy5GLvJLOMwG"
   },
   "outputs": [],
   "source": [
    "map1 = ['GASBG']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O2ehA-MsDTic"
   },
   "outputs": [],
   "source": [
    "map2 = ['GBSAG']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCJLBfV9OMwG",
    "outputId": "808d3920-cc60-4bcf-ef99-89a9bff447f9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GA\u001b[41mS\u001b[0mBG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env1 = gym.make('FrozenLake-v0', is_slippery=False, desc = map1)\n",
    "\n",
    "env1.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lsmP1zdHDlaG",
    "outputId": "f440f889-e790-45bd-fb6a-61f7eb564b0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GB\u001b[41mS\u001b[0mAG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env2 = gym.make('FrozenLake-v0', is_slippery=False, desc = map2)\n",
    "\n",
    "env2.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iKqlHWnqOMwH",
    "outputId": "5e76c51c-48f6-4b24-cec2-0469d6d5e072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States =  5\n",
      "Actions =  4\n"
     ]
    }
   ],
   "source": [
    "# Total number of States and Actions\n",
    "n_states = env1.observation_space.n\n",
    "n_actions = 4\n",
    "n_rows = 1\n",
    "n_cols = 5\n",
    "print( \"States = \", n_states)\n",
    "print( \"Actions = \", n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ETULzpcEc43",
    "outputId": "7b0757ea-858c-4d71-dcd1-522c25fb85a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States =  5\n",
      "Actions =  4\n"
     ]
    }
   ],
   "source": [
    "# Total number of States and Actions\n",
    "n_states = env2.observation_space.n\n",
    "n_actions = 4\n",
    "n_rows = 1\n",
    "n_cols = 5\n",
    "print( \"States = \", n_states)\n",
    "print( \"Actions = \", n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ew16IaBSPQDS"
   },
   "outputs": [],
   "source": [
    "def restrict_actions(Q, n_states, n_rows):\n",
    "\n",
    "  Q.at[n_states -1, :] = np.zeros(n_actions,)\n",
    "  Q.at[0, :] = np.zeros(n_actions,)\n",
    "  for i in range( 0, n_states, n_rows): \n",
    "    Q.at[i,0] = np.NaN\n",
    "  for i in range( n_rows -1 , n_states, n_rows): \n",
    "    Q.at[i,2] = np.NaN\n",
    "  for i in range(0, n_rows):\n",
    "    Q.at[i,3] = np.NaN\n",
    "  for i in range(n_states - n_rows , n_states):\n",
    "    Q.at[i,1 ]= np.NaN\n",
    "  \n",
    "  return Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "03DDjZsSPfX6"
   },
   "outputs": [],
   "source": [
    "def choose_action(Q, state, epsilon):\n",
    "  random_for_epsilon = np.random.rand()\n",
    "  if random_for_epsilon <= epsilon:\n",
    "    action = random.choice((0,2))\n",
    "  elif Q.loc[state,2] > Q.loc[state,0]: \n",
    "   action = 2\n",
    "  elif Q.loc[state,0] > Q.loc[state,2]: \n",
    "    action = 0\n",
    "  elif Q.loc[state,0] == Q.loc[state,2]: \n",
    "    action = random.choice((0,2))\n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5chvADGMW7FQ"
   },
   "outputs": [],
   "source": [
    "##assign index to each state using state-matrix\n",
    "\n",
    "state_matrix = np.arange(0,n_states).reshape(n_rows,n_cols)\n",
    "state_matrix\n",
    "\n",
    "def rowsandcols(state):\n",
    "  ''' input: state returned by env\n",
    "      output: location of state as (row,col) tuple'''\n",
    "  return int(np.where(state_matrix ==state)[0]), int(np.where(state_matrix ==state)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cCCqfNNCFq-E"
   },
   "outputs": [],
   "source": [
    "def rewarder1(new_state, reward, entrance_stimulus):\n",
    "\n",
    "  if entrance_stimulus == 'A':\n",
    "    if new_state == 0: \n",
    "      reward += 100\n",
    "    else:\n",
    "      reward -= 10\n",
    "\n",
    "  if entrance_stimulus == 'B':\n",
    "    if new_state == 4:\n",
    "      reward += 100\n",
    "    else:\n",
    "      reward -= 10\n",
    "\n",
    "  return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6ZRgtx3FV2hn"
   },
   "outputs": [],
   "source": [
    "def rewarder2(new_state, reward, entrance_stimulus):\n",
    "\n",
    "  if entrance_stimulus == 'A':\n",
    "    if new_state == 4:\n",
    "      reward += 100\n",
    "    else:\n",
    "      reward -= 10\n",
    "\n",
    "  if entrance_stimulus == 'B':\n",
    "    if new_state == 0:\n",
    "      reward += 100\n",
    "    else:\n",
    "      reward -= 10\n",
    "\n",
    "  return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "WOatlcLRMyfM"
   },
   "outputs": [],
   "source": [
    "reps = 1\n",
    "num_episodes = 1000\n",
    "steps_total = [] # store number of steps taken in each episode\n",
    "rewards_total = [] #store reward obtained for each episode\n",
    "epsilon_total = [] #store epsilon obtained at the end of each episode\n",
    "terminal_state = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBD20yPcOMwR"
   },
   "source": [
    "## q learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eKW0FxCaOMwR",
    "outputId": "2628afaf-0e7c-4aa5-f4c1-6c09e3c0f8b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 130 Reward: 70 Steps Taken: 4 , Epsilon: 0.4162724181202452, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 131 Reward: 90 Steps Taken: 2 , Epsilon: 0.41210969393904273, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 132 Reward: -20 Steps Taken: 2 , Epsilon: 0.41210969393904273, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 133 Reward: 90 Steps Taken: 2 , Epsilon: 0.4079885969996523, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 134 Reward: -20 Steps Taken: 2 , Epsilon: 0.4079885969996523, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 135 Reward: 90 Steps Taken: 2 , Epsilon: 0.40390871102965575, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 136 Reward: 90 Steps Taken: 2 , Epsilon: 0.40390871102965575, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 137 Reward: 90 Steps Taken: 2 , Epsilon: 0.3998696239193592, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 138 Reward: 90 Steps Taken: 2 , Epsilon: 0.3998696239193592, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 139 Reward: 90 Steps Taken: 2 , Epsilon: 0.39587092768016563, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 140 Reward: -20 Steps Taken: 2 , Epsilon: 0.39587092768016563, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 141 Reward: 90 Steps Taken: 2 , Epsilon: 0.391912218403364, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 142 Reward: 90 Steps Taken: 2 , Epsilon: 0.391912218403364, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 143 Reward: -20 Steps Taken: 2 , Epsilon: 0.38799309621933037, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 144 Reward: 90 Steps Taken: 2 , Epsilon: 0.38799309621933037, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 145 Reward: -40 Steps Taken: 4 , Epsilon: 0.38411316525713707, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 146 Reward: 90 Steps Taken: 2 , Epsilon: 0.38411316525713707, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 147 Reward: -40 Steps Taken: 4 , Epsilon: 0.3802720336045657, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 148 Reward: -40 Steps Taken: 4 , Epsilon: 0.3802720336045657, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 149 Reward: -20 Steps Taken: 2 , Epsilon: 0.37646931326852, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 150 Reward: -120 Steps Taken: 12 , Epsilon: 0.37646931326852, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 151 Reward: -20 Steps Taken: 2 , Epsilon: 0.37270462013583483, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 152 Reward: 90 Steps Taken: 2 , Epsilon: 0.37270462013583483, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 153 Reward: 90 Steps Taken: 2 , Epsilon: 0.3689775739344765, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 154 Reward: 90 Steps Taken: 2 , Epsilon: 0.3689775739344765, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 155 Reward: 90 Steps Taken: 2 , Epsilon: 0.36528779819513174, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 156 Reward: -20 Steps Taken: 2 , Epsilon: 0.36528779819513174, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 157 Reward: -20 Steps Taken: 2 , Epsilon: 0.36163492021318044, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 158 Reward: -20 Steps Taken: 2 , Epsilon: 0.36163492021318044, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 159 Reward: -20 Steps Taken: 2 , Epsilon: 0.3580185710110486, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 160 Reward: -20 Steps Taken: 2 , Epsilon: 0.3580185710110486, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 161 Reward: 90 Steps Taken: 2 , Epsilon: 0.35443838530093813, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 162 Reward: 90 Steps Taken: 2 , Epsilon: 0.35443838530093813, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 163 Reward: 90 Steps Taken: 2 , Epsilon: 0.35089400144792876, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 164 Reward: 90 Steps Taken: 2 , Epsilon: 0.35089400144792876, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 165 Reward: 90 Steps Taken: 2 , Epsilon: 0.3473850614334495, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 166 Reward: 70 Steps Taken: 4 , Epsilon: 0.3473850614334495, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 167 Reward: -20 Steps Taken: 2 , Epsilon: 0.343911210819115, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 168 Reward: -20 Steps Taken: 2 , Epsilon: 0.343911210819115, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 169 Reward: 90 Steps Taken: 2 , Epsilon: 0.3404720987109239, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 170 Reward: -20 Steps Taken: 2 , Epsilon: 0.3404720987109239, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 171 Reward: -60 Steps Taken: 6 , Epsilon: 0.3370673777238146, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 172 Reward: -20 Steps Taken: 2 , Epsilon: 0.3370673777238146, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 173 Reward: -20 Steps Taken: 2 , Epsilon: 0.33369670394657647, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 174 Reward: 90 Steps Taken: 2 , Epsilon: 0.33369670394657647, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 175 Reward: 90 Steps Taken: 2 , Epsilon: 0.3303597369071107, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 176 Reward: -20 Steps Taken: 2 , Epsilon: 0.3303597369071107, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 177 Reward: 90 Steps Taken: 2 , Epsilon: 0.3270561395380396, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 178 Reward: -20 Steps Taken: 2 , Epsilon: 0.3270561395380396, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 179 Reward: 90 Steps Taken: 2 , Epsilon: 0.3237855781426592, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 180 Reward: -20 Steps Taken: 2 , Epsilon: 0.3237855781426592, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 181 Reward: -40 Steps Taken: 4 , Epsilon: 0.3205477223612326, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 182 Reward: -40 Steps Taken: 4 , Epsilon: 0.3205477223612326, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 183 Reward: 90 Steps Taken: 2 , Epsilon: 0.31734224513762027, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 184 Reward: 90 Steps Taken: 2 , Epsilon: 0.31734224513762027, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 185 Reward: -20 Steps Taken: 2 , Epsilon: 0.3141688226862441, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 186 Reward: 70 Steps Taken: 4 , Epsilon: 0.3141688226862441, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 187 Reward: -20 Steps Taken: 2 , Epsilon: 0.3110271344593816, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 188 Reward: 70 Steps Taken: 4 , Epsilon: 0.3110271344593816, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 189 Reward: -40 Steps Taken: 4 , Epsilon: 0.30791686311478783, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 190 Reward: 70 Steps Taken: 4 , Epsilon: 0.30791686311478783, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 191 Reward: -20 Steps Taken: 2 , Epsilon: 0.30483769448363995, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 192 Reward: -20 Steps Taken: 2 , Epsilon: 0.30483769448363995, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 193 Reward: -80 Steps Taken: 8 , Epsilon: 0.30178931753880356, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 194 Reward: -60 Steps Taken: 6 , Epsilon: 0.30178931753880356, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 195 Reward: 90 Steps Taken: 2 , Epsilon: 0.2987714243634155, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 196 Reward: -20 Steps Taken: 2 , Epsilon: 0.2987714243634155, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 197 Reward: -20 Steps Taken: 2 , Epsilon: 0.2957837101197814, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 198 Reward: -40 Steps Taken: 4 , Epsilon: 0.2957837101197814, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 199 Reward: -40 Steps Taken: 4 , Epsilon: 0.2928258730185836, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 200 Reward: 90 Steps Taken: 2 , Epsilon: 0.2928258730185836, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 201 Reward: 90 Steps Taken: 2 , Epsilon: 0.2898976142883978, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 202 Reward: -20 Steps Taken: 2 , Epsilon: 0.2898976142883978, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 203 Reward: 90 Steps Taken: 2 , Epsilon: 0.2869986381455138, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 204 Reward: -40 Steps Taken: 4 , Epsilon: 0.2869986381455138, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 205 Reward: -20 Steps Taken: 2 , Epsilon: 0.28412865176405866, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 206 Reward: 70 Steps Taken: 4 , Epsilon: 0.28412865176405866, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 207 Reward: 70 Steps Taken: 4 , Epsilon: 0.28128736524641806, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 208 Reward: -20 Steps Taken: 2 , Epsilon: 0.28128736524641806, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 209 Reward: 90 Steps Taken: 2 , Epsilon: 0.2784744915939539, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 210 Reward: -20 Steps Taken: 2 , Epsilon: 0.2784744915939539, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 211 Reward: 90 Steps Taken: 2 , Epsilon: 0.2756897466780143, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 212 Reward: -20 Steps Taken: 2 , Epsilon: 0.2756897466780143, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 213 Reward: -20 Steps Taken: 2 , Epsilon: 0.2729328492112342, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 214 Reward: 90 Steps Taken: 2 , Epsilon: 0.2729328492112342, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 215 Reward: -20 Steps Taken: 2 , Epsilon: 0.27020352071912185, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 216 Reward: 90 Steps Taken: 2 , Epsilon: 0.27020352071912185, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 217 Reward: -40 Steps Taken: 4 , Epsilon: 0.26750148551193065, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 218 Reward: 90 Steps Taken: 2 , Epsilon: 0.26750148551193065, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 219 Reward: 90 Steps Taken: 2 , Epsilon: 0.26482647065681136, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 220 Reward: 90 Steps Taken: 2 , Epsilon: 0.26482647065681136, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 221 Reward: -40 Steps Taken: 4 , Epsilon: 0.26217820595024327, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 222 Reward: 70 Steps Taken: 4 , Epsilon: 0.26217820595024327, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 223 Reward: 90 Steps Taken: 2 , Epsilon: 0.25955642389074085, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 224 Reward: -20 Steps Taken: 2 , Epsilon: 0.25955642389074085, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 225 Reward: -20 Steps Taken: 2 , Epsilon: 0.25696085965183346, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 226 Reward: 70 Steps Taken: 4 , Epsilon: 0.25696085965183346, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 227 Reward: 90 Steps Taken: 2 , Epsilon: 0.2543912510553151, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 228 Reward: -20 Steps Taken: 2 , Epsilon: 0.2543912510553151, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 229 Reward: 30 Steps Taken: 8 , Epsilon: 0.251847338544762, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 230 Reward: 90 Steps Taken: 2 , Epsilon: 0.251847338544762, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 231 Reward: 90 Steps Taken: 2 , Epsilon: 0.24932886515931438, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 232 Reward: 90 Steps Taken: 2 , Epsilon: 0.24932886515931438, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 233 Reward: -20 Steps Taken: 2 , Epsilon: 0.24683557650772123, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 234 Reward: 90 Steps Taken: 2 , Epsilon: 0.24683557650772123, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 235 Reward: -20 Steps Taken: 2 , Epsilon: 0.24436722074264403, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 236 Reward: 90 Steps Taken: 2 , Epsilon: 0.24436722074264403, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 237 Reward: -20 Steps Taken: 2 , Epsilon: 0.24192354853521758, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 238 Reward: 90 Steps Taken: 2 , Epsilon: 0.24192354853521758, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 239 Reward: 90 Steps Taken: 2 , Epsilon: 0.2395043130498654, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 240 Reward: 70 Steps Taken: 4 , Epsilon: 0.2395043130498654, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 241 Reward: 90 Steps Taken: 2 , Epsilon: 0.23710926991936676, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 242 Reward: -20 Steps Taken: 2 , Epsilon: 0.23710926991936676, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 243 Reward: 50 Steps Taken: 6 , Epsilon: 0.2347381772201731, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 244 Reward: -20 Steps Taken: 2 , Epsilon: 0.2347381772201731, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 245 Reward: 90 Steps Taken: 2 , Epsilon: 0.23239079544797137, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 246 Reward: 90 Steps Taken: 2 , Epsilon: 0.23239079544797137, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 247 Reward: -20 Steps Taken: 2 , Epsilon: 0.23006688749349166, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 248 Reward: -20 Steps Taken: 2 , Epsilon: 0.23006688749349166, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 249 Reward: -20 Steps Taken: 2 , Epsilon: 0.22776621861855675, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 250 Reward: 90 Steps Taken: 2 , Epsilon: 0.22776621861855675, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 251 Reward: 70 Steps Taken: 4 , Epsilon: 0.22548855643237117, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 252 Reward: -20 Steps Taken: 2 , Epsilon: 0.22548855643237117, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 253 Reward: 90 Steps Taken: 2 , Epsilon: 0.22323367086804746, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 254 Reward: 90 Steps Taken: 2 , Epsilon: 0.22323367086804746, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 255 Reward: 90 Steps Taken: 2 , Epsilon: 0.22100133415936699, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 256 Reward: -20 Steps Taken: 2 , Epsilon: 0.22100133415936699, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 257 Reward: -20 Steps Taken: 2 , Epsilon: 0.2187913208177733, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 258 Reward: 70 Steps Taken: 4 , Epsilon: 0.2187913208177733, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 259 Reward: 70 Steps Taken: 4 , Epsilon: 0.21660340760959557, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 260 Reward: 90 Steps Taken: 2 , Epsilon: 0.21660340760959557, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 261 Reward: 90 Steps Taken: 2 , Epsilon: 0.21443737353349962, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 262 Reward: -20 Steps Taken: 2 , Epsilon: 0.21443737353349962, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 263 Reward: -40 Steps Taken: 4 , Epsilon: 0.21229299979816463, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 264 Reward: 70 Steps Taken: 4 , Epsilon: 0.21229299979816463, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 265 Reward: -40 Steps Taken: 4 , Epsilon: 0.210170069800183, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 266 Reward: 90 Steps Taken: 2 , Epsilon: 0.210170069800183, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 267 Reward: -40 Steps Taken: 4 , Epsilon: 0.20806836910218116, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 268 Reward: 50 Steps Taken: 6 , Epsilon: 0.20806836910218116, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 269 Reward: 90 Steps Taken: 2 , Epsilon: 0.20598768541115933, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 270 Reward: -20 Steps Taken: 2 , Epsilon: 0.20598768541115933, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 271 Reward: -20 Steps Taken: 2 , Epsilon: 0.20392780855704773, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 272 Reward: -40 Steps Taken: 4 , Epsilon: 0.20392780855704773, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 273 Reward: -20 Steps Taken: 2 , Epsilon: 0.20188853047147726, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 274 Reward: 90 Steps Taken: 2 , Epsilon: 0.20188853047147726, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 275 Reward: -20 Steps Taken: 2 , Epsilon: 0.19986964516676248, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 276 Reward: -20 Steps Taken: 2 , Epsilon: 0.19986964516676248, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 277 Reward: -20 Steps Taken: 2 , Epsilon: 0.19787094871509486, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 278 Reward: 90 Steps Taken: 2 , Epsilon: 0.19787094871509486, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 279 Reward: -20 Steps Taken: 2 , Epsilon: 0.1958922392279439, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 280 Reward: 90 Steps Taken: 2 , Epsilon: 0.1958922392279439, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 281 Reward: 90 Steps Taken: 2 , Epsilon: 0.19393331683566448, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 282 Reward: 90 Steps Taken: 2 , Epsilon: 0.19393331683566448, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 283 Reward: -20 Steps Taken: 2 , Epsilon: 0.19199398366730783, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 284 Reward: -20 Steps Taken: 2 , Epsilon: 0.19199398366730783, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 285 Reward: -20 Steps Taken: 2 , Epsilon: 0.19007404383063475, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 286 Reward: 90 Steps Taken: 2 , Epsilon: 0.19007404383063475, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 287 Reward: 90 Steps Taken: 2 , Epsilon: 0.1881733033923284, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 288 Reward: 90 Steps Taken: 2 , Epsilon: 0.1881733033923284, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 289 Reward: 90 Steps Taken: 2 , Epsilon: 0.18629157035840513, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 290 Reward: -40 Steps Taken: 4 , Epsilon: 0.18629157035840513, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 291 Reward: 90 Steps Taken: 2 , Epsilon: 0.18442865465482108, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 292 Reward: -40 Steps Taken: 4 , Epsilon: 0.18442865465482108, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 293 Reward: 70 Steps Taken: 4 , Epsilon: 0.18258436810827286, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 294 Reward: 50 Steps Taken: 6 , Epsilon: 0.18258436810827286, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 295 Reward: 90 Steps Taken: 2 , Epsilon: 0.18075852442719012, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 296 Reward: -40 Steps Taken: 4 , Epsilon: 0.18075852442719012, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 297 Reward: 50 Steps Taken: 6 , Epsilon: 0.1789509391829182, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 298 Reward: -20 Steps Taken: 2 , Epsilon: 0.1789509391829182, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 299 Reward: -20 Steps Taken: 2 , Epsilon: 0.17716142979108904, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 300 Reward: -20 Steps Taken: 2 , Epsilon: 0.17716142979108904, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 301 Reward: 90 Steps Taken: 2 , Epsilon: 0.17538981549317814, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 302 Reward: 70 Steps Taken: 4 , Epsilon: 0.17538981549317814, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 303 Reward: -20 Steps Taken: 2 , Epsilon: 0.17363591733824635, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 304 Reward: -20 Steps Taken: 2 , Epsilon: 0.17363591733824635, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 305 Reward: 90 Steps Taken: 2 , Epsilon: 0.17189955816486388, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 306 Reward: 90 Steps Taken: 2 , Epsilon: 0.17189955816486388, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 307 Reward: -20 Steps Taken: 2 , Epsilon: 0.17018056258321523, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 308 Reward: 90 Steps Taken: 2 , Epsilon: 0.17018056258321523, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 309 Reward: -20 Steps Taken: 2 , Epsilon: 0.16847875695738307, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 310 Reward: 90 Steps Taken: 2 , Epsilon: 0.16847875695738307, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 311 Reward: 90 Steps Taken: 2 , Epsilon: 0.16679396938780924, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 312 Reward: 90 Steps Taken: 2 , Epsilon: 0.16679396938780924, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 313 Reward: 90 Steps Taken: 2 , Epsilon: 0.16512602969393114, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 314 Reward: 90 Steps Taken: 2 , Epsilon: 0.16512602969393114, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 315 Reward: -20 Steps Taken: 2 , Epsilon: 0.16347476939699182, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 316 Reward: 90 Steps Taken: 2 , Epsilon: 0.16347476939699182, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 317 Reward: 90 Steps Taken: 2 , Epsilon: 0.1618400217030219, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 318 Reward: -20 Steps Taken: 2 , Epsilon: 0.1618400217030219, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 319 Reward: 90 Steps Taken: 2 , Epsilon: 0.16022162148599167, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 320 Reward: 90 Steps Taken: 2 , Epsilon: 0.16022162148599167, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 321 Reward: -20 Steps Taken: 2 , Epsilon: 0.15861940527113175, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 322 Reward: 90 Steps Taken: 2 , Epsilon: 0.15861940527113175, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 323 Reward: 90 Steps Taken: 2 , Epsilon: 0.15703321121842043, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 324 Reward: -20 Steps Taken: 2 , Epsilon: 0.15703321121842043, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 325 Reward: 90 Steps Taken: 2 , Epsilon: 0.1554628791062362, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 326 Reward: 70 Steps Taken: 4 , Epsilon: 0.1554628791062362, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 327 Reward: -20 Steps Taken: 2 , Epsilon: 0.15390825031517386, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 328 Reward: -40 Steps Taken: 4 , Epsilon: 0.15390825031517386, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 329 Reward: 90 Steps Taken: 2 , Epsilon: 0.15236916781202212, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 330 Reward: 90 Steps Taken: 2 , Epsilon: 0.15236916781202212, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 331 Reward: 90 Steps Taken: 2 , Epsilon: 0.1508454761339019, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 332 Reward: -20 Steps Taken: 2 , Epsilon: 0.1508454761339019, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 333 Reward: 70 Steps Taken: 4 , Epsilon: 0.14933702137256288, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 334 Reward: 50 Steps Taken: 6 , Epsilon: 0.14933702137256288, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 335 Reward: -20 Steps Taken: 2 , Epsilon: 0.14784365115883724, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 336 Reward: 90 Steps Taken: 2 , Epsilon: 0.14784365115883724, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 337 Reward: 90 Steps Taken: 2 , Epsilon: 0.14636521464724886, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 338 Reward: -20 Steps Taken: 2 , Epsilon: 0.14636521464724886, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 339 Reward: -20 Steps Taken: 2 , Epsilon: 0.14490156250077638, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 340 Reward: -20 Steps Taken: 2 , Epsilon: 0.14490156250077638, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 341 Reward: 90 Steps Taken: 2 , Epsilon: 0.1434525468757686, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 342 Reward: 50 Steps Taken: 6 , Epsilon: 0.1434525468757686, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 343 Reward: -20 Steps Taken: 2 , Epsilon: 0.14201802140701092, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 344 Reward: 70 Steps Taken: 4 , Epsilon: 0.14201802140701092, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 345 Reward: -20 Steps Taken: 2 , Epsilon: 0.1405978411929408, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 346 Reward: -20 Steps Taken: 2 , Epsilon: 0.1405978411929408, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 347 Reward: 90 Steps Taken: 2 , Epsilon: 0.1391918627810114, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 348 Reward: 90 Steps Taken: 2 , Epsilon: 0.1391918627810114, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 349 Reward: 90 Steps Taken: 2 , Epsilon: 0.1377999441532013, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 350 Reward: 90 Steps Taken: 2 , Epsilon: 0.1377999441532013, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 351 Reward: -20 Steps Taken: 2 , Epsilon: 0.13642194471166927, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 352 Reward: 90 Steps Taken: 2 , Epsilon: 0.13642194471166927, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 353 Reward: -40 Steps Taken: 4 , Epsilon: 0.13505772526455256, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 354 Reward: -60 Steps Taken: 6 , Epsilon: 0.13505772526455256, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 355 Reward: 90 Steps Taken: 2 , Epsilon: 0.13370714801190703, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 356 Reward: -20 Steps Taken: 2 , Epsilon: 0.13370714801190703, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 357 Reward: 90 Steps Taken: 2 , Epsilon: 0.13237007653178795, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 358 Reward: -20 Steps Taken: 2 , Epsilon: 0.13237007653178795, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 359 Reward: 90 Steps Taken: 2 , Epsilon: 0.13104637576647007, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 360 Reward: 90 Steps Taken: 2 , Epsilon: 0.13104637576647007, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 361 Reward: 90 Steps Taken: 2 , Epsilon: 0.12973591200880538, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 362 Reward: -20 Steps Taken: 2 , Epsilon: 0.12973591200880538, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 363 Reward: -20 Steps Taken: 2 , Epsilon: 0.12843855288871733, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 364 Reward: -20 Steps Taken: 2 , Epsilon: 0.12843855288871733, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 365 Reward: 90 Steps Taken: 2 , Epsilon: 0.12715416735983015, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 366 Reward: 90 Steps Taken: 2 , Epsilon: 0.12715416735983015, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 367 Reward: -20 Steps Taken: 2 , Epsilon: 0.12588262568623185, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 368 Reward: -20 Steps Taken: 2 , Epsilon: 0.12588262568623185, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 369 Reward: -20 Steps Taken: 2 , Epsilon: 0.12462379942936953, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 370 Reward: 90 Steps Taken: 2 , Epsilon: 0.12462379942936953, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 371 Reward: -20 Steps Taken: 2 , Epsilon: 0.12337756143507583, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 372 Reward: 90 Steps Taken: 2 , Epsilon: 0.12337756143507583, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 373 Reward: 70 Steps Taken: 4 , Epsilon: 0.12214378582072508, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 374 Reward: 90 Steps Taken: 2 , Epsilon: 0.12214378582072508, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 375 Reward: 90 Steps Taken: 2 , Epsilon: 0.12092234796251783, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 376 Reward: 90 Steps Taken: 2 , Epsilon: 0.12092234796251783, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 377 Reward: -20 Steps Taken: 2 , Epsilon: 0.11971312448289265, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 378 Reward: -40 Steps Taken: 4 , Epsilon: 0.11971312448289265, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 379 Reward: 90 Steps Taken: 2 , Epsilon: 0.11851599323806372, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 380 Reward: -40 Steps Taken: 4 , Epsilon: 0.11851599323806372, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 381 Reward: 90 Steps Taken: 2 , Epsilon: 0.11733083330568309, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 382 Reward: 90 Steps Taken: 2 , Epsilon: 0.11733083330568309, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 383 Reward: 90 Steps Taken: 2 , Epsilon: 0.11615752497262626, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 384 Reward: 90 Steps Taken: 2 , Epsilon: 0.11615752497262626, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 385 Reward: -20 Steps Taken: 2 , Epsilon: 0.11499594972289999, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 386 Reward: 90 Steps Taken: 2 , Epsilon: 0.11499594972289999, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 387 Reward: -20 Steps Taken: 2 , Epsilon: 0.11384599022567099, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 388 Reward: 70 Steps Taken: 4 , Epsilon: 0.11384599022567099, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 389 Reward: 90 Steps Taken: 2 , Epsilon: 0.11270753032341428, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 390 Reward: -20 Steps Taken: 2 , Epsilon: 0.11270753032341428, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 391 Reward: 50 Steps Taken: 6 , Epsilon: 0.11158045502018014, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 392 Reward: 90 Steps Taken: 2 , Epsilon: 0.11158045502018014, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 393 Reward: 90 Steps Taken: 2 , Epsilon: 0.11046465046997835, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 394 Reward: 90 Steps Taken: 2 , Epsilon: 0.11046465046997835, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 395 Reward: 90 Steps Taken: 2 , Epsilon: 0.10936000396527856, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 396 Reward: 90 Steps Taken: 2 , Epsilon: 0.10936000396527856, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 397 Reward: -20 Steps Taken: 2 , Epsilon: 0.10826640392562578, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 398 Reward: 90 Steps Taken: 2 , Epsilon: 0.10826640392562578, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 399 Reward: 90 Steps Taken: 2 , Epsilon: 0.10718373988636952, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 400 Reward: -20 Steps Taken: 2 , Epsilon: 0.10718373988636952, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 401 Reward: 90 Steps Taken: 2 , Epsilon: 0.10611190248750582, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 402 Reward: 90 Steps Taken: 2 , Epsilon: 0.10611190248750582, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 403 Reward: 90 Steps Taken: 2 , Epsilon: 0.10505078346263076, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 404 Reward: 90 Steps Taken: 2 , Epsilon: 0.10505078346263076, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 405 Reward: -40 Steps Taken: 4 , Epsilon: 0.10400027562800446, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 406 Reward: -40 Steps Taken: 4 , Epsilon: 0.10400027562800446, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 407 Reward: -20 Steps Taken: 2 , Epsilon: 0.1029602728717244, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 408 Reward: 70 Steps Taken: 4 , Epsilon: 0.1029602728717244, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 409 Reward: -40 Steps Taken: 4 , Epsilon: 0.10193067014300716, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 410 Reward: 70 Steps Taken: 4 , Epsilon: 0.10193067014300716, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 411 Reward: -20 Steps Taken: 2 , Epsilon: 0.10091136344157708, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 412 Reward: -40 Steps Taken: 4 , Epsilon: 0.10091136344157708, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 413 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 414 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 415 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 416 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 417 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 418 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 419 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 420 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 421 Reward: 50 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 422 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 423 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 424 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 425 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 426 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 427 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 428 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 429 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 430 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 431 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 432 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 433 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 434 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 435 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 436 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 437 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 438 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 439 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 440 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 441 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 442 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 443 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 444 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 445 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 446 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 447 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 448 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 449 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 450 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 451 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 452 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 453 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 454 Reward: -80 Steps Taken: 8 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 455 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 456 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 457 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 458 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 459 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 460 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 461 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 462 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 463 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 464 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 465 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 466 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 467 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 468 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 469 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 470 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 471 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 472 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 473 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 474 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 475 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 476 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 477 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 478 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 479 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 480 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 481 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 482 Reward: 50 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 483 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 484 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 485 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 486 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 487 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 488 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 489 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 490 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 491 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 492 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 493 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 494 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 495 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 496 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 497 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 498 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 499 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 500 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 501 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 502 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 503 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 504 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 505 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 506 Reward: -60 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 507 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 508 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 509 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 510 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 511 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 512 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 513 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 514 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 515 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 516 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 517 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 518 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 519 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 520 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 521 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 522 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 523 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 524 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 525 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 526 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 527 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 528 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 529 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 530 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 531 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 532 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 533 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 534 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 535 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 536 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 537 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 538 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 539 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 540 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 541 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 542 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 543 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 544 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 545 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 546 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 547 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 548 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 549 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 550 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 551 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 552 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 553 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 554 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 555 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 556 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 557 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 558 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 559 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 560 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 561 Reward: 50 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 562 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 563 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 564 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 565 Reward: 50 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 566 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 567 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 568 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 569 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 570 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 571 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 572 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 573 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 574 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 575 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 576 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 577 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 578 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 579 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 580 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 581 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 582 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 583 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 584 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 585 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 586 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 587 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 588 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 589 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 590 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 591 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 592 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 593 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 594 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 595 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 596 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 597 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 598 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 599 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 600 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 601 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 602 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 603 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 604 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 605 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 606 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 607 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 608 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 609 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 610 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 611 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 612 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 613 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 614 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 615 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 616 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 617 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 618 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 619 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 620 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 621 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 622 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 623 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 624 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 625 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 626 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 627 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 628 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 629 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 630 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 631 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 632 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 633 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 634 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 635 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 636 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 637 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 638 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 639 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 640 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 641 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 642 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 643 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 644 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 645 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 646 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 647 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 648 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 649 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 650 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 651 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 652 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 653 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 654 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 655 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 656 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 657 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 658 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 659 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 660 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 661 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 662 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 663 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 664 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 665 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 666 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 667 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 668 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 669 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 670 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 671 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 672 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 673 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 674 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 675 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 676 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 677 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 678 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 679 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 680 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 681 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 682 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 683 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 684 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 685 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 686 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 687 Reward: -60 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 688 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 689 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 690 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 691 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 692 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 693 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 694 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 695 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 696 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 697 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 698 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 699 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 700 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 701 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 702 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 703 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 704 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 705 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 706 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 707 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 708 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 709 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 710 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 711 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 712 Reward: -60 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 713 Reward: -60 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 714 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 715 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 716 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 717 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 718 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 719 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 720 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 721 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 722 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 723 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 724 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 725 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 726 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 727 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 728 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 729 Reward: 50 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 730 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 731 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 732 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 733 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 734 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 735 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 736 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 737 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 738 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 739 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 740 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 741 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 742 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 743 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 744 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 745 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 746 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 747 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 748 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 749 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 750 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 751 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 752 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 753 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 754 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 755 Reward: -60 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 756 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 757 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 758 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 759 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 760 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 761 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 762 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 763 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 764 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 765 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 766 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 767 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 768 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 769 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 770 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 771 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 772 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 773 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 774 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 775 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 776 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 777 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 778 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 779 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 780 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 781 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 782 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 783 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 784 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 785 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 786 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 787 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 788 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 789 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 790 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 791 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 792 Reward: 50 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 793 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 794 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 795 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 796 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 797 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 798 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 799 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 800 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 801 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 802 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 803 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 804 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 805 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 806 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 807 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Right)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 808 Reward: 30 Steps Taken: 8 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 809 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 810 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 811 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 812 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 813 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 814 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 815 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 816 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 817 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 818 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 819 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 820 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 821 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 822 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 823 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 824 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 825 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 826 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 827 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 828 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 829 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 830 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 831 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 832 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 833 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 834 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 835 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 836 Reward: -60 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 837 Reward: -60 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 838 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 839 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 840 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 841 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 842 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 843 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 844 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 845 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 846 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 847 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 848 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 849 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 850 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 851 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 852 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 853 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 854 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 855 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 856 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 857 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 858 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 859 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 860 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 861 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 862 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 863 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 864 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 865 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 866 Reward: 50 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 867 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 868 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 869 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 870 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 871 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 872 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 873 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 874 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 875 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 876 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 877 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 878 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 879 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 880 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 881 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 882 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 883 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 884 Reward: 50 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 885 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 886 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 887 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 888 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 889 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 890 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 891 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 892 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 893 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 894 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 895 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 896 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 897 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 898 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 899 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 900 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 901 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 902 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 903 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 904 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 905 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 906 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 907 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 908 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 909 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 910 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 911 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 912 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 913 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 914 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 915 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 916 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 917 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 918 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 919 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 920 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 921 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 922 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 923 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 924 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 925 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 926 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 927 Reward: -60 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 928 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 929 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 930 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 931 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 932 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 933 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 934 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 935 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 936 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 937 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 938 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 939 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 940 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 941 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 942 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 943 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 944 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 945 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 946 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 947 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 948 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 949 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 950 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 951 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 952 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 953 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 954 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 955 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 956 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 957 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 958 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 959 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 960 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 961 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 962 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 963 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 964 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 965 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 966 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 967 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 968 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 969 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 970 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Left)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Right)\n",
      "GBS\u001b[41mA\u001b[0mG\n",
      "  (Right)\n",
      "GBSA\u001b[41mG\u001b[0m\n",
      "Episode: 971 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Left)\n",
      "GA\u001b[41mS\u001b[0mBG\n",
      "  (Right)\n",
      "GAS\u001b[41mB\u001b[0mG\n",
      "  (Right)\n",
      "GASB\u001b[41mG\u001b[0m\n",
      "Episode: 972 Reward: 50 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 973 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 974 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 975 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 976 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 977 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 978 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 979 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 980 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 981 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 982 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 983 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 984 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 985 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 986 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 987 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 988 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 989 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 990 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 991 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 992 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 993 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 994 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 995 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 996 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 997 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
      "  (Left)\n",
      "G\u001b[41mA\u001b[0mSBG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mASBG\n",
      "Episode: 998 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment: ['GASBG']\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Right)\n",
      "GB\u001b[41mS\u001b[0mAG\n",
      "  (Left)\n",
      "G\u001b[41mB\u001b[0mSAG\n",
      "  (Left)\n",
      "\u001b[41mG\u001b[0mBSAG\n",
      "Episode: 999 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n"
     ]
    }
   ],
   "source": [
    "for i in range(reps):\n",
    "  \n",
    "  epsilon = 0.8\n",
    "  epsilon_final = 0.1\n",
    "  epsilon_decay = 0.99\n",
    "\n",
    "  gamma = 0.90 # discount factor\n",
    "  learning_rate = 0.9 #how important is the difference between q-val from q-table and what's observed\n",
    "\n",
    "  Q = pd.DataFrame(np.random.rand(n_states,n_actions)/1000)\n",
    "  #Q .loc[n_states-1] = np.zeros(n_actions,)\n",
    "  #Q.loc[n_cols-1] = np.zeros(n_actions,) \n",
    "  #Q = restrict_actions(Q, 5, 1)\n",
    "\n",
    "  for i_episode in range(num_episodes):\n",
    "\n",
    "    if np.random.randn() > 0.5: \n",
    "      entrance_stimulus = 'A'\n",
    "    else: \n",
    "      entrance_stimulus = 'B'\n",
    "\n",
    "    if epsilon > epsilon_final and i_episode%2!=0:\n",
    "            epsilon *= epsilon_decay\n",
    "\n",
    "\n",
    "    # resets the environment\n",
    "    \n",
    "    \n",
    "    if i_episode%2==0:\n",
    "      state = env1.reset()\n",
    "      step = 0\n",
    "      reward = 0\n",
    "\n",
    "      while True:\n",
    "        step += 1\n",
    "\n",
    "        random_for_epsilon = np.random.randn()\n",
    "\n",
    "        action = choose_action(Q, state, epsilon)\n",
    "        \n",
    "\n",
    "         \n",
    "        ## env gives reward and next state and whether we've reached terminal state upon taking action at current state.. \n",
    "        new_state, _ , done, info = env1.step(action)\n",
    "\n",
    "        ##if you want reward penalized at for each timestep\n",
    "        reward = rewarder1(new_state, reward, entrance_stimulus)\n",
    "\n",
    "        \n",
    "        # filling the Q Table - \n",
    "        \n",
    "        Q.loc[state, action] = (1- learning_rate)*(Q.at[state, action]) + (learning_rate)*(reward+ gamma*(np.max(Q.loc[new_state, [0,2]])))\n",
    "        \n",
    "        # Setting new state for next action\n",
    "        state = new_state\n",
    "        env1.render()\n",
    "\n",
    "        if done:\n",
    "          print('Episode: {} Reward: {} Steps Taken: {} , Epsilon: {}, Entrance_Stimulus: {}, Environment: {}'.format(i_episode,reward, step,  epsilon, entrance_stimulus, map1  ))\n",
    "          steps_total.append(step)\n",
    "          break\n",
    "\n",
    "    else:\n",
    "      state = env2.reset()\n",
    "      step = 0\n",
    "      reward = 0\n",
    "\n",
    "      while True:\n",
    "        step += 1\n",
    "\n",
    "        random_for_epsilon = np.random.randn()\n",
    "\n",
    "        action = choose_action(Q, state, epsilon)\n",
    "        \n",
    "\n",
    "         \n",
    "        ## env gives reward and next state and whether we've reached terminal state upon taking action at current state.. \n",
    "        new_state, _ , done, info = env2.step(action)\n",
    "\n",
    "        ##if you want reward penalized at for each timestep\n",
    "        reward = rewarder2(new_state, reward, entrance_stimulus)\n",
    "\n",
    "        \n",
    "        # filling the Q Table - \n",
    "        \n",
    "        Q.loc[state, action] = (1- learning_rate)*(Q.at[state, action]) + (learning_rate)*(reward+ gamma*(np.max(Q.loc[new_state, [0,2]])))\n",
    "        \n",
    "        # Setting new state for next action\n",
    "        state = new_state\n",
    "        env2.render()\n",
    "\n",
    "\n",
    "        if done:\n",
    "          print('Episode: {} Reward: {} Steps Taken: {} , Epsilon: {}, Entrance_Stimulus: {}, Environment:{} '.format(i_episode,reward, step,  epsilon, entrance_stimulus, map2 ))\n",
    "          steps_total.append(step)\n",
    "          break\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "w8fAyKNVR2i9",
    "outputId": "4009c852-5801-41ea-c697-87089fa7bb49"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.000827</td>\n",
       "      <td>-23.509911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-11.635620</td>\n",
       "      <td>-58.477067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.734579</td>\n",
       "      <td>-55.045986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.000521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          2\n",
       "0   0.000146   0.000918\n",
       "1  80.000827 -23.509911\n",
       "2 -11.635620 -58.477067\n",
       "3 -44.734579 -55.045986\n",
       "4   0.000907   0.000521"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.loc[:, [0,2]]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DMST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
